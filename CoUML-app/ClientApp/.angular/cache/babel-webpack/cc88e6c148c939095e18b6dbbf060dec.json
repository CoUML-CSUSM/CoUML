{"ast":null,"code":"const {\n  parseOpId,\n  copyObject\n} = require('../src/common');\n\nconst {\n  COLUMN_TYPE,\n  VALUE_TYPE,\n  ACTIONS,\n  OBJECT_TYPE,\n  DOC_OPS_COLUMNS,\n  CHANGE_COLUMNS,\n  DOCUMENT_COLUMNS,\n  encoderByColumnId,\n  decoderByColumnId,\n  makeDecoders,\n  decodeValue,\n  encodeChange,\n  decodeChangeColumns,\n  decodeChangeMeta,\n  decodeChanges,\n  decodeDocumentHeader,\n  encodeDocumentHeader\n} = require('./columnar');\n\nconst MAX_BLOCK_SIZE = 600; // operations\n\nconst BLOOM_BITS_PER_ENTRY = 10,\n      BLOOM_NUM_PROBES = 7; // 1% false positive rate\n\nconst BLOOM_FILTER_SIZE = Math.floor(BLOOM_BITS_PER_ENTRY * MAX_BLOCK_SIZE / 8); // bytes\n\nconst objActorIdx = 0,\n      objCtrIdx = 1,\n      keyActorIdx = 2,\n      keyCtrIdx = 3,\n      keyStrIdx = 4,\n      idActorIdx = 5,\n      idCtrIdx = 6,\n      insertIdx = 7,\n      actionIdx = 8,\n      valLenIdx = 9,\n      valRawIdx = 10,\n      predNumIdx = 13,\n      predActorIdx = 14,\n      predCtrIdx = 15,\n      succNumIdx = 13,\n      succActorIdx = 14,\n      succCtrIdx = 15;\nconst PRED_COLUMN_IDS = CHANGE_COLUMNS.filter(column => ['predNum', 'predActor', 'predCtr'].includes(column.columnName)).map(column => column.columnId);\n/**\n * Updates `objectTree`, which is a tree of nested objects, so that afterwards\n * `objectTree[path[0]][path[1]][...] === value`. Only the root object is mutated, whereas any\n * nested objects are copied before updating. This means that once the root object has been\n * shallow-copied, this function can be used to update it without mutating the previous version.\n */\n\nfunction deepCopyUpdate(objectTree, path, value) {\n  if (path.length === 1) {\n    objectTree[path[0]] = value;\n  } else {\n    let child = Object.assign({}, objectTree[path[0]]);\n    deepCopyUpdate(child, path.slice(1), value);\n    objectTree[path[0]] = child;\n  }\n}\n/**\n * Scans a block of document operations, encoded as columns `docCols`, to find the position at which\n * an operation (or sequence of operations) `ops` should be applied. `actorIds` is the array that\n * maps actor numbers to hexadecimal actor IDs. `resumeInsertion` is true if we're performing a list\n * insertion and we already found the reference element in a previous block, but we reached the end\n * of that previous block while scanning for the actual insertion position, and so we're continuing\n * the scan in a subsequent block.\n *\n * Returns an object with keys:\n * - `found`: false if we were scanning for a reference element in a list but couldn't find it;\n *    true otherwise.\n * - `skipCount`: the number of operations, counted from the start of the block, after which the\n *   new operations should be inserted or applied.\n * - `visibleCount`: if modifying a list object, the number of visible (i.e. non-deleted) list\n *   elements that precede the position where the new operations should be applied.\n */\n\n\nfunction seekWithinBlock(ops, docCols, actorIds, resumeInsertion) {\n  for (let col of docCols) col.decoder.reset();\n\n  const {\n    objActor,\n    objCtr,\n    keyActor,\n    keyCtr,\n    keyStr,\n    idActor,\n    idCtr,\n    insert\n  } = ops;\n  const [\n    /* keyActorD */\n\n    /* keyCtrD */\n\n    /* valLenD */\n\n    /* valRawD */\n\n    /* chldActorD */\n\n    /* chldCtrD */\n  objActorD, objCtrD,,, keyStrD, idActorD, idCtrD, insertD, actionD,,,,, succNumD] = docCols.map(col => col.decoder);\n  let skipCount = 0,\n      visibleCount = 0,\n      elemVisible = false,\n      nextObjActor = null,\n      nextObjCtr = null;\n  let nextIdActor = null,\n      nextIdCtr = null,\n      nextKeyStr = null,\n      nextInsert = null,\n      nextSuccNum = 0; // Seek to the beginning of the object being updated\n\n  if (objCtr !== null && !resumeInsertion) {\n    while (!objCtrD.done || !objActorD.done || !actionD.done) {\n      nextObjCtr = objCtrD.readValue();\n      nextObjActor = actorIds[objActorD.readValue()];\n      actionD.skipValues(1);\n\n      if (nextObjCtr === null || !nextObjActor || nextObjCtr < objCtr || nextObjCtr === objCtr && nextObjActor < objActor) {\n        skipCount += 1;\n      } else {\n        break;\n      }\n    }\n  }\n\n  if ((nextObjCtr !== objCtr || nextObjActor !== objActor) && !resumeInsertion) {\n    return {\n      found: true,\n      skipCount,\n      visibleCount\n    };\n  } // Seek to the appropriate key (if string key is used)\n\n\n  if (keyStr !== null) {\n    keyStrD.skipValues(skipCount);\n\n    while (!keyStrD.done) {\n      const objActorIndex = objActorD.readValue();\n      nextObjActor = objActorIndex === null ? null : actorIds[objActorIndex];\n      nextObjCtr = objCtrD.readValue();\n      nextKeyStr = keyStrD.readValue();\n\n      if (nextKeyStr !== null && nextKeyStr < keyStr && nextObjCtr === objCtr && nextObjActor === objActor) {\n        skipCount += 1;\n      } else {\n        break;\n      }\n    }\n\n    return {\n      found: true,\n      skipCount,\n      visibleCount\n    };\n  }\n\n  idCtrD.skipValues(skipCount);\n  idActorD.skipValues(skipCount);\n  insertD.skipValues(skipCount);\n  succNumD.skipValues(skipCount);\n  nextIdCtr = idCtrD.readValue();\n  nextIdActor = actorIds[idActorD.readValue()];\n  nextInsert = insertD.readValue();\n  nextSuccNum = succNumD.readValue(); // If we are inserting into a list, an opId key is used, and we need to seek to a position *after*\n  // the referenced operation. Moreover, we need to skip over any existing operations with a greater\n  // opId than the new insertion, for CRDT convergence on concurrent insertions in the same place.\n\n  if (insert) {\n    // If insertion is not at the head, search for the reference element\n    if (!resumeInsertion && keyCtr !== null && keyCtr > 0 && keyActor !== null) {\n      skipCount += 1;\n\n      while (!idCtrD.done && !idActorD.done && (nextIdCtr !== keyCtr || nextIdActor !== keyActor)) {\n        if (nextInsert) elemVisible = false;\n\n        if (nextSuccNum === 0 && !elemVisible) {\n          visibleCount += 1;\n          elemVisible = true;\n        }\n\n        nextIdCtr = idCtrD.readValue();\n        nextIdActor = actorIds[idActorD.readValue()];\n        nextObjCtr = objCtrD.readValue();\n        nextObjActor = actorIds[objActorD.readValue()];\n        nextInsert = insertD.readValue();\n        nextSuccNum = succNumD.readValue();\n        if (nextObjCtr === objCtr && nextObjActor === objActor) skipCount += 1;else break;\n      }\n\n      if (nextObjCtr !== objCtr || nextObjActor !== objActor || nextIdCtr !== keyCtr || nextIdActor !== keyActor || !nextInsert) {\n        return {\n          found: false,\n          skipCount,\n          visibleCount\n        };\n      }\n\n      if (nextInsert) elemVisible = false;\n\n      if (nextSuccNum === 0 && !elemVisible) {\n        visibleCount += 1;\n        elemVisible = true;\n      } // Set up the next* variables to the operation following the reference element\n\n\n      if (idCtrD.done || idActorD.done) return {\n        found: true,\n        skipCount,\n        visibleCount\n      };\n      nextIdCtr = idCtrD.readValue();\n      nextIdActor = actorIds[idActorD.readValue()];\n      nextObjCtr = objCtrD.readValue();\n      nextObjActor = actorIds[objActorD.readValue()];\n      nextInsert = insertD.readValue();\n      nextSuccNum = succNumD.readValue();\n    } // Skip over any list elements with greater ID than the new one, and any non-insertions\n\n\n    while ((!nextInsert || nextIdCtr > idCtr || nextIdCtr === idCtr && nextIdActor > idActor) && nextObjCtr === objCtr && nextObjActor === objActor) {\n      skipCount += 1;\n      if (nextInsert) elemVisible = false;\n\n      if (nextSuccNum === 0 && !elemVisible) {\n        visibleCount += 1;\n        elemVisible = true;\n      }\n\n      if (!idCtrD.done && !idActorD.done) {\n        nextIdCtr = idCtrD.readValue();\n        nextIdActor = actorIds[idActorD.readValue()];\n        nextObjCtr = objCtrD.readValue();\n        nextObjActor = actorIds[objActorD.readValue()];\n        nextInsert = insertD.readValue();\n        nextSuccNum = succNumD.readValue();\n      } else {\n        break;\n      }\n    }\n  } else if (keyCtr !== null && keyCtr > 0 && keyActor !== null) {\n    // If we are updating an existing list element, seek to just before the referenced ID\n    while ((!nextInsert || nextIdCtr !== keyCtr || nextIdActor !== keyActor) && nextObjCtr === objCtr && nextObjActor === objActor) {\n      skipCount += 1;\n      if (nextInsert) elemVisible = false;\n\n      if (nextSuccNum === 0 && !elemVisible) {\n        visibleCount += 1;\n        elemVisible = true;\n      }\n\n      if (!idCtrD.done && !idActorD.done) {\n        nextIdCtr = idCtrD.readValue();\n        nextIdActor = actorIds[idActorD.readValue()];\n        nextObjCtr = objCtrD.readValue();\n        nextObjActor = actorIds[objActorD.readValue()];\n        nextInsert = insertD.readValue();\n        nextSuccNum = succNumD.readValue();\n      } else {\n        break;\n      }\n    }\n\n    if (nextObjCtr !== objCtr || nextObjActor !== objActor || nextIdCtr !== keyCtr || nextIdActor !== keyActor || !nextInsert) {\n      return {\n        found: false,\n        skipCount,\n        visibleCount\n      };\n    }\n  }\n\n  return {\n    found: true,\n    skipCount,\n    visibleCount\n  };\n}\n/**\n * Returns the number of list elements that should be added to a list index when skipping over the\n * block with index `blockIndex` in the list object with object ID consisting of actor number\n * `objActorNum` and counter `objCtr`.\n */\n\n\nfunction visibleListElements(docState, blockIndex, objActorNum, objCtr) {\n  const thisBlock = docState.blocks[blockIndex];\n  const nextBlock = docState.blocks[blockIndex + 1];\n\n  if (thisBlock.lastObjectActor !== objActorNum || thisBlock.lastObjectCtr !== objCtr || thisBlock.numVisible === undefined) {\n    return 0; // If a list element is split across the block boundary, don't double-count it\n  } else if (thisBlock.lastVisibleActor === nextBlock.firstVisibleActor && thisBlock.lastVisibleActor !== undefined && thisBlock.lastVisibleCtr === nextBlock.firstVisibleCtr && thisBlock.lastVisibleCtr !== undefined) {\n    return thisBlock.numVisible - 1;\n  } else {\n    return thisBlock.numVisible;\n  }\n}\n/**\n * Scans the blocks of document operations to find the position where a new operation should be\n * inserted. Returns an object with keys:\n * - `blockIndex`: the index of the block into which we should insert the new operation\n * - `skipCount`: the number of operations, counted from the start of the block, after which the\n *   new operations should be inserted or merged.\n * - `visibleCount`: if modifying a list object, the number of visible (i.e. non-deleted) list\n *   elements that precede the position where the new operations should be applied.\n */\n\n\nfunction seekToOp(docState, ops) {\n  const {\n    objActor,\n    objActorNum,\n    objCtr,\n    keyActor,\n    keyCtr,\n    keyStr\n  } = ops;\n  let blockIndex = 0,\n      totalVisible = 0; // Skip any blocks that contain only objects with lower objectIds\n\n  if (objCtr !== null) {\n    while (blockIndex < docState.blocks.length - 1) {\n      const blockActor = docState.blocks[blockIndex].lastObjectActor === undefined ? undefined : docState.actorIds[docState.blocks[blockIndex].lastObjectActor];\n      const blockCtr = docState.blocks[blockIndex].lastObjectCtr;\n\n      if (blockCtr === null || blockCtr < objCtr || blockCtr === objCtr && blockActor < objActor) {\n        blockIndex++;\n      } else {\n        break;\n      }\n    }\n  }\n\n  if (keyStr !== null) {\n    // String key is used. First skip any blocks that contain only lower keys\n    while (blockIndex < docState.blocks.length - 1) {\n      const {\n        lastObjectActor,\n        lastObjectCtr,\n        lastKey\n      } = docState.blocks[blockIndex];\n      if (objCtr === lastObjectCtr && objActorNum === lastObjectActor && lastKey !== undefined && lastKey < keyStr) blockIndex++;else break;\n    } // When we have a candidate block, decode it to find the exact insertion position\n\n\n    const {\n      skipCount\n    } = seekWithinBlock(ops, docState.blocks[blockIndex].columns, docState.actorIds, false);\n    return {\n      blockIndex,\n      skipCount,\n      visibleCount: 0\n    };\n  } else {\n    // List operation\n    const insertAtHead = keyCtr === null || keyCtr === 0 || keyActor === null;\n    const keyActorNum = keyActor === null ? null : docState.actorIds.indexOf(keyActor);\n    let resumeInsertion = false;\n\n    while (true) {\n      // Search for the reference element, skipping any blocks whose Bloom filter does not contain\n      // the reference element. We only do this if not inserting at the head (in which case there is\n      // no reference element), or if we already found the reference element in an earlier block (in\n      // which case we have resumeInsertion === true). The latter case arises with concurrent\n      // insertions at the same position, and so we have to scan beyond the reference element to\n      // find the actual insertion position, and that further scan crosses a block boundary.\n      if (!insertAtHead && !resumeInsertion) {\n        while (blockIndex < docState.blocks.length - 1 && docState.blocks[blockIndex].lastObjectActor === objActorNum && docState.blocks[blockIndex].lastObjectCtr === objCtr && !bloomFilterContains(docState.blocks[blockIndex].bloom, keyActorNum, keyCtr)) {\n          // If we reach the end of the list object without a Bloom filter hit, the reference element\n          // doesn't exist\n          if (docState.blocks[blockIndex].lastObjectCtr > objCtr) {\n            throw new RangeError(`Reference element not found: ${keyCtr}@${keyActor}`);\n          } // Add up number of visible list elements in any blocks we skip, for list index computation\n\n\n          totalVisible += visibleListElements(docState, blockIndex, objActorNum, objCtr);\n          blockIndex++;\n        }\n      } // We have a candidate block. Decode it to see whether it really contains the reference element\n\n\n      const {\n        found,\n        skipCount,\n        visibleCount\n      } = seekWithinBlock(ops, docState.blocks[blockIndex].columns, docState.actorIds, resumeInsertion);\n\n      if (blockIndex === docState.blocks.length - 1 || docState.blocks[blockIndex].lastObjectActor !== objActorNum || docState.blocks[blockIndex].lastObjectCtr !== objCtr) {\n        // Last block: if we haven't found the reference element by now, it's an error\n        if (found) {\n          return {\n            blockIndex,\n            skipCount,\n            visibleCount: totalVisible + visibleCount\n          };\n        } else {\n          throw new RangeError(`Reference element not found: ${keyCtr}@${keyActor}`);\n        }\n      } else if (found && skipCount < docState.blocks[blockIndex].numOps) {\n        // The insertion position lies within the current block\n        return {\n          blockIndex,\n          skipCount,\n          visibleCount: totalVisible + visibleCount\n        };\n      } // Reference element not found and there are still blocks left ==> it was probably a false positive.\n      // Reference element found, but we skipped all the way to the end of the block ==> we need to\n      // continue scanning the next block to find the actual insertion position.\n      // Either way, go back round the loop again to skip blocks until the next Bloom filter hit.\n\n\n      resumeInsertion = found && ops.insert;\n      totalVisible += visibleListElements(docState, blockIndex, objActorNum, objCtr);\n      blockIndex++;\n    }\n  }\n}\n/**\n * Updates Bloom filter `bloom`, given as a Uint8Array, to contain the list element ID consisting of\n * counter `elemIdCtr` and actor number `elemIdActor`. We don't actually bother computing a hash\n * function, since those two integers serve perfectly fine as input. We turn the two integers into a\n * sequence of probe indexes using the triple hashing algorithm from the following paper:\n *\n * Peter C. Dillinger and Panagiotis Manolios. Bloom Filters in Probabilistic Verification.\n * 5th International Conference on Formal Methods in Computer-Aided Design (FMCAD), November 2004.\n * http://www.ccis.northeastern.edu/home/pete/pub/bloom-filters-verification.pdf\n */\n\n\nfunction bloomFilterAdd(bloom, elemIdActor, elemIdCtr) {\n  let modulo = 8 * bloom.byteLength,\n      x = elemIdCtr % modulo,\n      y = elemIdActor % modulo; // Use one step of FNV-1a to compute a third value from the two inputs.\n  // Taken from http://www.isthe.com/chongo/tech/comp/fnv/index.html\n  // The prime is just over 2^24, so elemIdCtr can be up to about 2^29 = 500 million before the\n  // result of the multiplication exceeds 2^53. And even if it does exceed 2^53 and loses precision,\n  // that shouldn't be a problem as it should still be deterministic, and the Bloom filter\n  // computation only needs to be internally consistent within this library.\n\n  let z = ((elemIdCtr ^ elemIdActor) * 16777619 >>> 0) % modulo;\n\n  for (let i = 0; i < BLOOM_NUM_PROBES; i++) {\n    bloom[x >>> 3] |= 1 << (x & 7);\n    x = (x + y) % modulo;\n    y = (y + z) % modulo;\n  }\n}\n/**\n * Returns true if the list element ID consisting of counter `elemIdCtr` and actor number\n * `elemIdActor` is likely to be contained in the Bloom filter `bloom`.\n */\n\n\nfunction bloomFilterContains(bloom, elemIdActor, elemIdCtr) {\n  let modulo = 8 * bloom.byteLength,\n      x = elemIdCtr % modulo,\n      y = elemIdActor % modulo;\n  let z = ((elemIdCtr ^ elemIdActor) * 16777619 >>> 0) % modulo; // See comments in the bloomFilterAdd function for an explanation\n\n  for (let i = 0; i < BLOOM_NUM_PROBES; i++) {\n    if ((bloom[x >>> 3] & 1 << (x & 7)) === 0) {\n      return false;\n    }\n\n    x = (x + y) % modulo;\n    y = (y + z) % modulo;\n  }\n\n  return true;\n}\n/**\n * Reads the relevant columns of a block of operations and updates that block to contain the\n * metadata we need to efficiently figure out where to insert new operations.\n */\n\n\nfunction updateBlockMetadata(block) {\n  block.bloom = new Uint8Array(BLOOM_FILTER_SIZE);\n  block.numOps = 0;\n  block.lastKey = undefined;\n  block.numVisible = undefined;\n  block.lastObjectActor = undefined;\n  block.lastObjectCtr = undefined;\n  block.firstVisibleActor = undefined;\n  block.firstVisibleCtr = undefined;\n  block.lastVisibleActor = undefined;\n  block.lastVisibleCtr = undefined;\n\n  for (let col of block.columns) col.decoder.reset();\n\n  const [\n    /* actionD */\n\n    /* valLenD */\n\n    /* valRawD */\n\n    /* chldActorD */\n\n    /* chldCtrD */\n  objActorD, objCtrD, keyActorD, keyCtrD, keyStrD, idActorD, idCtrD, insertD,,,,,, succNumD] = block.columns.map(col => col.decoder);\n\n  while (!idCtrD.done) {\n    block.numOps += 1;\n    const objActor = objActorD.readValue(),\n          objCtr = objCtrD.readValue();\n    const keyActor = keyActorD.readValue(),\n          keyCtr = keyCtrD.readValue(),\n          keyStr = keyStrD.readValue();\n    const idActor = idActorD.readValue(),\n          idCtr = idCtrD.readValue();\n    const insert = insertD.readValue(),\n          succNum = succNumD.readValue();\n\n    if (block.lastObjectActor !== objActor || block.lastObjectCtr !== objCtr) {\n      block.numVisible = 0;\n      block.lastObjectActor = objActor;\n      block.lastObjectCtr = objCtr;\n    }\n\n    if (keyStr !== null) {\n      // Map key: for each object, record the highest key contained in the block\n      block.lastKey = keyStr;\n    } else if (insert || keyCtr !== null) {\n      // List element\n      block.lastKey = undefined;\n      const elemIdActor = insert ? idActor : keyActor;\n      const elemIdCtr = insert ? idCtr : keyCtr;\n      bloomFilterAdd(block.bloom, elemIdActor, elemIdCtr); // If the list element is visible, update the block metadata accordingly\n\n      if (succNum === 0) {\n        if (block.firstVisibleActor === undefined) block.firstVisibleActor = elemIdActor;\n        if (block.firstVisibleCtr === undefined) block.firstVisibleCtr = elemIdCtr;\n\n        if (block.lastVisibleActor !== elemIdActor || block.lastVisibleCtr !== elemIdCtr) {\n          block.numVisible += 1;\n          block.lastVisibleActor = elemIdActor;\n          block.lastVisibleCtr = elemIdCtr;\n        }\n      }\n    }\n  }\n}\n/**\n * Updates a block's metadata based on an operation being added to a block.\n */\n\n\nfunction addBlockOperation(block, op, actorIds, isChangeOp) {\n  if (op[keyStrIdx] !== null) {\n    // TODO this comparison should use UTF-8 encoding, not JavaScript's UTF-16\n    if (block.lastObjectCtr === op[objCtrIdx] && block.lastObjectActor === op[objActorIdx] && (block.lastKey === undefined || block.lastKey < op[keyStrIdx])) {\n      block.lastKey = op[keyStrIdx];\n    }\n  } else {\n    // List element\n    const elemIdActor = op[insertIdx] ? op[idActorIdx] : op[keyActorIdx];\n    const elemIdCtr = op[insertIdx] ? op[idCtrIdx] : op[keyCtrIdx];\n    bloomFilterAdd(block.bloom, elemIdActor, elemIdCtr); // Set lastVisible on the assumption that this is the last op in the block; if there are further\n    // ops after this one in the block, lastVisible will be overwritten again later.\n\n    if (op[succNumIdx] === 0 || isChangeOp) {\n      if (block.firstVisibleActor === undefined) block.firstVisibleActor = elemIdActor;\n      if (block.firstVisibleCtr === undefined) block.firstVisibleCtr = elemIdCtr;\n      block.lastVisibleActor = elemIdActor;\n      block.lastVisibleCtr = elemIdCtr;\n    }\n  } // Keep track of the largest objectId contained within a block\n\n\n  if (block.lastObjectCtr === undefined || op[objActorIdx] !== null && op[objCtrIdx] !== null && (block.lastObjectCtr === null || block.lastObjectCtr < op[objCtrIdx] || block.lastObjectCtr === op[objCtrIdx] && actorIds[block.lastObjectActor] < actorIds[op[objActorIdx]])) {\n    block.lastObjectActor = op[objActorIdx];\n    block.lastObjectCtr = op[objCtrIdx];\n    block.lastKey = op[keyStrIdx] !== null ? op[keyStrIdx] : undefined;\n    block.numVisible = 0;\n  }\n}\n/**\n * Takes a block containing too many operations, and splits it into a sequence of adjacent blocks of\n * roughly equal size.\n */\n\n\nfunction splitBlock(block) {\n  for (let col of block.columns) col.decoder.reset(); // Make each of the resulting blocks between 50% and 80% full (leaving a bit of space in each\n  // block so that it doesn't get split again right away the next time an operation is added).\n  // The upper bound cannot be lower than 75% since otherwise we would end up with a block less than\n  // 50% full when going from two to three blocks.\n\n\n  const numBlocks = Math.ceil(block.numOps / (0.8 * MAX_BLOCK_SIZE));\n  let blocks = [],\n      opsSoFar = 0;\n\n  for (let i = 1; i <= numBlocks; i++) {\n    const opsToCopy = Math.ceil(i * block.numOps / numBlocks) - opsSoFar;\n    const encoders = block.columns.map(col => ({\n      columnId: col.columnId,\n      encoder: encoderByColumnId(col.columnId)\n    }));\n    copyColumns(encoders, block.columns, opsToCopy);\n    const decoders = encoders.map(col => {\n      const decoder = decoderByColumnId(col.columnId, col.encoder.buffer);\n      return {\n        columnId: col.columnId,\n        decoder\n      };\n    });\n    const newBlock = {\n      columns: decoders\n    };\n    updateBlockMetadata(newBlock);\n    blocks.push(newBlock);\n    opsSoFar += opsToCopy;\n  }\n\n  return blocks;\n}\n/**\n * Takes an array of blocks and concatenates the corresponding columns across all of the blocks.\n */\n\n\nfunction concatBlocks(blocks) {\n  const encoders = blocks[0].columns.map(col => ({\n    columnId: col.columnId,\n    encoder: encoderByColumnId(col.columnId)\n  }));\n\n  for (let block of blocks) {\n    for (let col of block.columns) col.decoder.reset();\n\n    copyColumns(encoders, block.columns, block.numOps);\n  }\n\n  return encoders;\n}\n/**\n * Copies `count` rows from the set of input columns `inCols` to the set of output columns\n * `outCols`. The input columns are given as an array of `{columnId, decoder}` objects, and the\n * output columns are given as an array of `{columnId, encoder}` objects. Both are sorted in\n * increasing order of columnId. If there is no matching input column for a given output column, it\n * is filled in with `count` blank values (according to the column type).\n */\n\n\nfunction copyColumns(outCols, inCols, count) {\n  if (count === 0) return;\n  let inIndex = 0,\n      lastGroup = -1,\n      lastCardinality = 0,\n      valueColumn = -1,\n      valueBytes = 0;\n\n  for (let outCol of outCols) {\n    while (inIndex < inCols.length && inCols[inIndex].columnId < outCol.columnId) inIndex++;\n\n    let inCol = null;\n\n    if (inIndex < inCols.length && inCols[inIndex].columnId === outCol.columnId && inCols[inIndex].decoder.buf.byteLength > 0) {\n      inCol = inCols[inIndex].decoder;\n    }\n\n    const colCount = outCol.columnId >> 4 === lastGroup ? lastCardinality : count;\n\n    if (outCol.columnId % 8 === COLUMN_TYPE.GROUP_CARD) {\n      lastGroup = outCol.columnId >> 4;\n\n      if (inCol) {\n        lastCardinality = outCol.encoder.copyFrom(inCol, {\n          count,\n          sumValues: true\n        }).sum;\n      } else {\n        outCol.encoder.appendValue(0, count);\n        lastCardinality = 0;\n      }\n    } else if (outCol.columnId % 8 === COLUMN_TYPE.VALUE_LEN) {\n      if (inCol) {\n        if (inIndex + 1 === inCols.length || inCols[inIndex + 1].columnId !== outCol.columnId + 1) {\n          throw new RangeError('VALUE_LEN column without accompanying VALUE_RAW column');\n        }\n\n        valueColumn = outCol.columnId + 1;\n        valueBytes = outCol.encoder.copyFrom(inCol, {\n          count: colCount,\n          sumValues: true,\n          sumShift: 4\n        }).sum;\n      } else {\n        outCol.encoder.appendValue(null, colCount);\n        valueColumn = outCol.columnId + 1;\n        valueBytes = 0;\n      }\n    } else if (outCol.columnId % 8 === COLUMN_TYPE.VALUE_RAW) {\n      if (outCol.columnId !== valueColumn) {\n        throw new RangeError('VALUE_RAW column without accompanying VALUE_LEN column');\n      }\n\n      if (valueBytes > 0) {\n        outCol.encoder.appendRawBytes(inCol.readRawBytes(valueBytes));\n      }\n    } else {\n      // ACTOR_ID, INT_RLE, INT_DELTA, BOOLEAN, or STRING_RLE\n      if (inCol) {\n        outCol.encoder.copyFrom(inCol, {\n          count: colCount\n        });\n      } else {\n        const blankValue = outCol.columnId % 8 === COLUMN_TYPE.BOOLEAN ? false : null;\n        outCol.encoder.appendValue(blankValue, colCount);\n      }\n    }\n  }\n}\n/**\n * Parses one operation from a set of columns. The argument `columns` contains a list of objects\n * with `columnId` and `decoder` properties. Returns an array in which the i'th element is the\n * value read from the i'th column in `columns`. Does not interpret datatypes; the only\n * interpretation of values is that if `actorTable` is given, a value `v` in a column of type\n * ACTOR_ID is replaced with `actorTable[v]`.\n */\n\n\nfunction readOperation(columns, actorTable) {\n  let operation = [],\n      colValue,\n      lastGroup = -1,\n      lastCardinality = 0,\n      valueColumn = -1,\n      valueBytes = 0;\n\n  for (let col of columns) {\n    if (col.columnId % 8 === COLUMN_TYPE.VALUE_RAW) {\n      if (col.columnId !== valueColumn) throw new RangeError('unexpected VALUE_RAW column');\n      colValue = col.decoder.readRawBytes(valueBytes);\n    } else if (col.columnId % 8 === COLUMN_TYPE.GROUP_CARD) {\n      lastGroup = col.columnId >> 4;\n      lastCardinality = col.decoder.readValue() || 0;\n      colValue = lastCardinality;\n    } else if (col.columnId >> 4 === lastGroup) {\n      colValue = [];\n\n      if (col.columnId % 8 === COLUMN_TYPE.VALUE_LEN) {\n        valueColumn = col.columnId + 1;\n        valueBytes = 0;\n      }\n\n      for (let i = 0; i < lastCardinality; i++) {\n        let value = col.decoder.readValue();\n\n        if (col.columnId % 8 === COLUMN_TYPE.ACTOR_ID && actorTable && typeof value === 'number') {\n          value = actorTable[value];\n        }\n\n        if (col.columnId % 8 === COLUMN_TYPE.VALUE_LEN) {\n          valueBytes += colValue >>> 4;\n        }\n\n        colValue.push(value);\n      }\n    } else {\n      colValue = col.decoder.readValue();\n\n      if (col.columnId % 8 === COLUMN_TYPE.ACTOR_ID && actorTable && typeof colValue === 'number') {\n        colValue = actorTable[colValue];\n      }\n\n      if (col.columnId % 8 === COLUMN_TYPE.VALUE_LEN) {\n        valueColumn = col.columnId + 1;\n        valueBytes = colValue >>> 4;\n      }\n    }\n\n    operation.push(colValue);\n  }\n\n  return operation;\n}\n/**\n * Appends `operation`, in the form returned by `readOperation()`, to the columns in `outCols`. The\n * argument `inCols` provides metadata about the types of columns in `operation`; the value\n * `operation[i]` comes from the column `inCols[i]`.\n */\n\n\nfunction appendOperation(outCols, inCols, operation) {\n  let inIndex = 0,\n      lastGroup = -1,\n      lastCardinality = 0;\n\n  for (let outCol of outCols) {\n    while (inIndex < inCols.length && inCols[inIndex].columnId < outCol.columnId) inIndex++;\n\n    if (inIndex < inCols.length && inCols[inIndex].columnId === outCol.columnId) {\n      const colValue = operation[inIndex];\n\n      if (outCol.columnId % 8 === COLUMN_TYPE.GROUP_CARD) {\n        lastGroup = outCol.columnId >> 4;\n        lastCardinality = colValue;\n        outCol.encoder.appendValue(colValue);\n      } else if (outCol.columnId >> 4 === lastGroup) {\n        if (!Array.isArray(colValue) || colValue.length !== lastCardinality) {\n          throw new RangeError('bad group value');\n        }\n\n        for (let v of colValue) outCol.encoder.appendValue(v);\n      } else if (outCol.columnId % 8 === COLUMN_TYPE.VALUE_RAW) {\n        if (colValue) outCol.encoder.appendRawBytes(colValue);\n      } else {\n        outCol.encoder.appendValue(colValue);\n      }\n    } else if (outCol.columnId % 8 === COLUMN_TYPE.GROUP_CARD) {\n      lastGroup = outCol.columnId >> 4;\n      lastCardinality = 0;\n      outCol.encoder.appendValue(0);\n    } else if (outCol.columnId % 8 !== COLUMN_TYPE.VALUE_RAW) {\n      const count = outCol.columnId >> 4 === lastGroup ? lastCardinality : 1;\n      let blankValue = null;\n      if (outCol.columnId % 8 === COLUMN_TYPE.BOOLEAN) blankValue = false;\n      if (outCol.columnId % 8 === COLUMN_TYPE.VALUE_LEN) blankValue = 0;\n      outCol.encoder.appendValue(blankValue, count);\n    }\n  }\n}\n/**\n * Parses the next operation from block `blockIndex` of the document. Returns an object of the form\n * `{docOp, blockIndex}` where `docOp` is an operation in the form returned by `readOperation()`,\n * and `blockIndex` is the block number to use on the next call (it moves on to the next block when\n * we reach the end of the current block). `docOp` is null if there are no more operations.\n */\n\n\nfunction readNextDocOp(docState, blockIndex) {\n  let block = docState.blocks[blockIndex];\n\n  if (!block.columns[actionIdx].decoder.done) {\n    return {\n      docOp: readOperation(block.columns),\n      blockIndex\n    };\n  } else if (blockIndex === docState.blocks.length - 1) {\n    return {\n      docOp: null,\n      blockIndex\n    };\n  } else {\n    blockIndex += 1;\n    block = docState.blocks[blockIndex];\n\n    for (let col of block.columns) col.decoder.reset();\n\n    return {\n      docOp: readOperation(block.columns),\n      blockIndex\n    };\n  }\n}\n/**\n * Parses the next operation from a sequence of changes. `changeState` serves as the state of this\n * pseudo-iterator, and it is mutated to reflect the new operation. In particular,\n * `changeState.nextOp` is set to the operation that was read, and `changeState.done` is set to true\n * when we have finished reading the last operation in the last change.\n */\n\n\nfunction readNextChangeOp(docState, changeState) {\n  // If we've finished reading one change, move to the next change that contains at least one op\n  while (changeState.changeIndex < changeState.changes.length - 1 && (!changeState.columns || changeState.columns[actionIdx].decoder.done)) {\n    changeState.changeIndex += 1;\n    const change = changeState.changes[changeState.changeIndex];\n    changeState.columns = makeDecoders(change.columns, CHANGE_COLUMNS);\n    changeState.opCtr = change.startOp; // Update docState based on the information in the change\n\n    updateBlockColumns(docState, changeState.columns);\n    const {\n      actorIds,\n      actorTable\n    } = getActorTable(docState.actorIds, change);\n    docState.actorIds = actorIds;\n    changeState.actorTable = actorTable;\n    changeState.actorIndex = docState.actorIds.indexOf(change.actorIds[0]);\n  } // Reached the end of the last change?\n\n\n  if (changeState.columns[actionIdx].decoder.done) {\n    changeState.done = true;\n    changeState.nextOp = null;\n    return;\n  }\n\n  changeState.nextOp = readOperation(changeState.columns, changeState.actorTable);\n  changeState.nextOp[idActorIdx] = changeState.actorIndex;\n  changeState.nextOp[idCtrIdx] = changeState.opCtr;\n  changeState.changes[changeState.changeIndex].maxOp = changeState.opCtr;\n  if (changeState.opCtr > docState.maxOp) docState.maxOp = changeState.opCtr;\n  changeState.opCtr += 1;\n  const op = changeState.nextOp;\n\n  if (op[objCtrIdx] === null && op[objActorIdx] !== null || op[objCtrIdx] !== null && op[objActorIdx] === null) {\n    throw new RangeError(`Mismatched object reference: (${op[objCtrIdx]}, ${op[objActorIdx]})`);\n  }\n\n  if (op[keyCtrIdx] === null && op[keyActorIdx] !== null || op[keyCtrIdx] === 0 && op[keyActorIdx] !== null || op[keyCtrIdx] > 0 && op[keyActorIdx] === null) {\n    throw new RangeError(`Mismatched operation key: (${op[keyCtrIdx]}, ${op[keyActorIdx]})`);\n  }\n}\n\nfunction emptyObjectPatch(objectId, type) {\n  if (type === 'list' || type === 'text') {\n    return {\n      objectId,\n      type,\n      edits: []\n    };\n  } else {\n    return {\n      objectId,\n      type,\n      props: {}\n    };\n  }\n}\n/**\n * Returns true if the two given operation IDs have the same actor ID, and the counter of `id2` is\n * exactly `delta` greater than the counter of `id1`.\n */\n\n\nfunction opIdDelta(id1, id2, delta = 1) {\n  const parsed1 = parseOpId(id1),\n        parsed2 = parseOpId(id2);\n  return parsed1.actorId === parsed2.actorId && parsed1.counter + delta === parsed2.counter;\n}\n/**\n * Appends a list edit operation (insert, update, remove) to an array of existing operations. If the\n * last existing operation can be extended (as a multi-op), we do that.\n */\n\n\nfunction appendEdit(existingEdits, nextEdit) {\n  if (existingEdits.length === 0) {\n    existingEdits.push(nextEdit);\n    return;\n  }\n\n  let lastEdit = existingEdits[existingEdits.length - 1];\n\n  if (lastEdit.action === 'insert' && nextEdit.action === 'insert' && lastEdit.index === nextEdit.index - 1 && lastEdit.value.type === 'value' && nextEdit.value.type === 'value' && lastEdit.elemId === lastEdit.opId && nextEdit.elemId === nextEdit.opId && opIdDelta(lastEdit.elemId, nextEdit.elemId, 1) && lastEdit.value.datatype === nextEdit.value.datatype && typeof lastEdit.value.value === typeof nextEdit.value.value) {\n    lastEdit.action = 'multi-insert';\n    if (nextEdit.value.datatype) lastEdit.datatype = nextEdit.value.datatype;\n    lastEdit.values = [lastEdit.value.value, nextEdit.value.value];\n    delete lastEdit.value;\n    delete lastEdit.opId;\n  } else if (lastEdit.action === 'multi-insert' && nextEdit.action === 'insert' && lastEdit.index + lastEdit.values.length === nextEdit.index && nextEdit.value.type === 'value' && nextEdit.elemId === nextEdit.opId && opIdDelta(lastEdit.elemId, nextEdit.elemId, lastEdit.values.length) && lastEdit.datatype === nextEdit.value.datatype && typeof lastEdit.values[0] === typeof nextEdit.value.value) {\n    lastEdit.values.push(nextEdit.value.value);\n  } else if (lastEdit.action === 'remove' && nextEdit.action === 'remove' && lastEdit.index === nextEdit.index) {\n    lastEdit.count += nextEdit.count;\n  } else {\n    existingEdits.push(nextEdit);\n  }\n}\n/**\n * `edits` is an array of (SingleInsertEdit | MultiInsertEdit | UpdateEdit | RemoveEdit) list edits\n * for a patch. This function appends an UpdateEdit to this array. A conflict is represented by\n * having several consecutive edits with the same index, and this can be realised by calling\n * `appendUpdate` several times for the same list element. On the first such call, `firstUpdate`\n * must be true.\n *\n * It is possible that coincidentally the previous edit (potentially arising from a different\n * change) is for the same index. If this is the case, to avoid accidentally treating consecutive\n * updates for the same index as a conflict, we remove the previous edit for the same index. This is\n * safe because the previous edit is overwritten by the new edit being appended, and we know that\n * it's for the same list elements because there are no intervening insertions/deletions that could\n * have changed the indexes.\n */\n\n\nfunction appendUpdate(edits, index, elemId, opId, value, firstUpdate) {\n  let insert = false;\n\n  if (firstUpdate) {\n    // Pop all edits for the same index off the end of the edits array. This sequence may begin with\n    // either an insert or an update. If it's an insert, we remember that fact, and use it below.\n    while (!insert && edits.length > 0) {\n      const lastEdit = edits[edits.length - 1];\n\n      if ((lastEdit.action === 'insert' || lastEdit.action === 'update') && lastEdit.index === index) {\n        edits.pop();\n        insert = lastEdit.action === 'insert';\n      } else if (lastEdit.action === 'multi-insert' && lastEdit.index + lastEdit.values.length - 1 === index) {\n        lastEdit.values.pop();\n        insert = true;\n      } else {\n        break;\n      }\n    }\n  } // If we popped an insert edit off the edits array, we need to turn the new update into an insert\n  // in order to ensure the list element still gets inserted (just with a new value).\n\n\n  if (insert) {\n    appendEdit(edits, {\n      action: 'insert',\n      index,\n      elemId,\n      opId,\n      value\n    });\n  } else {\n    appendEdit(edits, {\n      action: 'update',\n      index,\n      opId,\n      value\n    });\n  }\n}\n/**\n * `edits` is an array of (SingleInsertEdit | MultiInsertEdit | UpdateEdit | RemoveEdit) list edits\n * for a patch. We assume that there is a suffix of this array that consists of an insertion at\n * position `index`, followed by zero or more UpdateEdits at the same index. This function rewrites\n * that suffix to be all updates instead. This is needed because sometimes when generating a patch\n * we think we are performing a list insertion, but then it later turns out that there was already\n * an existing value at that list element, and so we actually need to do an update, not an insert.\n *\n * If the suffix is preceded by one or more updates at the same index, those earlier updates are\n * removed by `appendUpdate()` to ensure we don't inadvertently treat them as part of the same\n * conflict.\n */\n\n\nfunction convertInsertToUpdate(edits, index, elemId) {\n  let updates = [];\n\n  while (edits.length > 0) {\n    let lastEdit = edits[edits.length - 1];\n\n    if (lastEdit.action === 'insert') {\n      if (lastEdit.index !== index) throw new RangeError('last edit has unexpected index');\n      updates.unshift(edits.pop());\n      break;\n    } else if (lastEdit.action === 'update') {\n      if (lastEdit.index !== index) throw new RangeError('last edit has unexpected index');\n      updates.unshift(edits.pop());\n    } else {\n      // It's impossible to encounter a remove edit here because the state machine in\n      // updatePatchProperty() ensures that a property can have either an insert or a remove edit,\n      // but not both. It's impossible to encounter a multi-insert here because multi-inserts always\n      // have equal elemId and opId (i.e. they can only be used for the operation that first inserts\n      // an element, but not for any subsequent assignments to that list element); moreover,\n      // convertInsertToUpdate is only called if an insert action is followed by a non-overwritten\n      // document op. The fact that there is a non-overwritten document op after another op on the\n      // same list element implies that the original insertion op for that list element must be\n      // overwritten, and thus the original insertion op cannot have given rise to a multi-insert.\n      throw new RangeError('last edit has unexpected action');\n    }\n  } // Now take the edits we popped off and push them back onto the list again\n\n\n  let firstUpdate = true;\n\n  for (let update of updates) {\n    appendUpdate(edits, index, elemId, update.opId, update.value, firstUpdate);\n    firstUpdate = false;\n  }\n}\n/**\n * Updates `patches` to reflect the operation `op` within the document with state `docState`.\n * Can be called multiple times if there are multiple operations for the same property (e.g. due\n * to a conflict). `propState` is an object that carries over state between such successive\n * invocations for the same property. If the current object is a list, `listIndex` is the index\n * into that list (counting only visible elements). If the operation `op` was already previously\n * in the document, `oldSuccNum` is the value of `op[succNumIdx]` before the current change was\n * applied (allowing us to determine whether this operation was overwritten or deleted in the\n * current change). `oldSuccNum` must be undefined if the operation came from the current change.\n * If we are creating an incremental patch as a result of applying one or more changes, `newBlock`\n * is the block to which the operations are getting written; we will update the metadata on this\n * block. `newBlock` should be null if we are creating a patch for the whole document.\n */\n\n\nfunction updatePatchProperty(patches, newBlock, objectId, op, docState, propState, listIndex, oldSuccNum) {\n  const isWholeDoc = !newBlock;\n  const type = op[actionIdx] < ACTIONS.length ? OBJECT_TYPE[ACTIONS[op[actionIdx]]] : null;\n  const opId = `${op[idCtrIdx]}@${docState.actorIds[op[idActorIdx]]}`;\n  const elemIdActor = op[insertIdx] ? op[idActorIdx] : op[keyActorIdx];\n  const elemIdCtr = op[insertIdx] ? op[idCtrIdx] : op[keyCtrIdx];\n  const elemId = op[keyStrIdx] ? op[keyStrIdx] : `${elemIdCtr}@${docState.actorIds[elemIdActor]}`; // When the change contains a new make* operation (i.e. with an even-numbered action), record the\n  // new parent-child relationship in objectMeta. TODO: also handle link/move operations.\n\n  if (op[actionIdx] % 2 === 0 && !docState.objectMeta[opId]) {\n    docState.objectMeta[opId] = {\n      parentObj: objectId,\n      parentKey: elemId,\n      opId,\n      type,\n      children: {}\n    };\n    deepCopyUpdate(docState.objectMeta, [objectId, 'children', elemId, opId], {\n      objectId: opId,\n      type,\n      props: {}\n    });\n  } // firstOp is true if the current operation is the first of a sequence of ops for the same key\n\n\n  const firstOp = !propState[elemId];\n  if (!propState[elemId]) propState[elemId] = {\n    visibleOps: [],\n    hasChild: false\n  }; // An operation is overwritten if it is a document operation that has at least one successor\n\n  const isOverwritten = oldSuccNum !== undefined && op[succNumIdx] > 0; // Record all visible values for the property, and whether it has any child object\n\n  if (!isOverwritten) {\n    propState[elemId].visibleOps.push(op);\n    propState[elemId].hasChild = propState[elemId].hasChild || op[actionIdx] % 2 === 0; // even-numbered action == make* operation\n  } // If one or more of the values of the property is a child object, we update objectMeta to store\n  // all of the visible values of the property (even the non-child-object values). Then, when we\n  // subsequently process an update within that child object, we can construct the patch to\n  // contain the conflicting values.\n\n\n  const prevChildren = docState.objectMeta[objectId].children[elemId];\n\n  if (propState[elemId].hasChild || prevChildren && Object.keys(prevChildren).length > 0) {\n    let values = {};\n\n    for (let visible of propState[elemId].visibleOps) {\n      const opId = `${visible[idCtrIdx]}@${docState.actorIds[visible[idActorIdx]]}`;\n\n      if (ACTIONS[visible[actionIdx]] === 'set') {\n        values[opId] = Object.assign({\n          type: 'value'\n        }, decodeValue(visible[valLenIdx], visible[valRawIdx]));\n      } else if (visible[actionIdx] % 2 === 0) {\n        const objType = visible[actionIdx] < ACTIONS.length ? OBJECT_TYPE[ACTIONS[visible[actionIdx]]] : null;\n        values[opId] = emptyObjectPatch(opId, objType);\n      }\n    } // Copy so that objectMeta is not modified if an exception is thrown while applying change\n\n\n    deepCopyUpdate(docState.objectMeta, [objectId, 'children', elemId], values);\n  }\n\n  let patchKey, patchValue; // For counters, increment operations are succs to the set operation that created the counter,\n  // but in this case we want to add the values rather than overwriting them.\n\n  if (isOverwritten && ACTIONS[op[actionIdx]] === 'set' && (op[valLenIdx] & 0x0f) === VALUE_TYPE.COUNTER) {\n    // This is the initial set operation that creates a counter. Initialise the counter state\n    // to contain all successors of the set operation. Only if we later find that each of these\n    // successor operations is an increment, we make the counter visible in the patch.\n    if (!propState[elemId]) propState[elemId] = {\n      visibleOps: [],\n      hasChild: false\n    };\n    if (!propState[elemId].counterStates) propState[elemId].counterStates = {};\n    let counterStates = propState[elemId].counterStates;\n    let counterState = {\n      opId,\n      value: decodeValue(op[valLenIdx], op[valRawIdx]).value,\n      succs: {}\n    };\n\n    for (let i = 0; i < op[succNumIdx]; i++) {\n      const succOp = `${op[succCtrIdx][i]}@${docState.actorIds[op[succActorIdx][i]]}`;\n      counterStates[succOp] = counterState;\n      counterState.succs[succOp] = true;\n    }\n  } else if (ACTIONS[op[actionIdx]] === 'inc') {\n    // Incrementing a previously created counter.\n    if (!propState[elemId] || !propState[elemId].counterStates || !propState[elemId].counterStates[opId]) {\n      throw new RangeError(`increment operation ${opId} for unknown counter`);\n    }\n\n    let counterState = propState[elemId].counterStates[opId];\n    counterState.value += decodeValue(op[valLenIdx], op[valRawIdx]).value;\n    delete counterState.succs[opId];\n\n    if (Object.keys(counterState.succs).length === 0) {\n      patchKey = counterState.opId;\n      patchValue = {\n        type: 'value',\n        datatype: 'counter',\n        value: counterState.value\n      }; // TODO if the counter is in a list element, we need to add a 'remove' action when deleted\n    }\n  } else if (!isOverwritten) {\n    // Add the value to the patch if it is not overwritten (i.e. if it has no succs).\n    if (ACTIONS[op[actionIdx]] === 'set') {\n      patchKey = opId;\n      patchValue = Object.assign({\n        type: 'value'\n      }, decodeValue(op[valLenIdx], op[valRawIdx]));\n    } else if (op[actionIdx] % 2 === 0) {\n      // even-numbered action == make* operation\n      if (!patches[opId]) patches[opId] = emptyObjectPatch(opId, type);\n      patchKey = opId;\n      patchValue = patches[opId];\n    }\n  }\n\n  if (!patches[objectId]) patches[objectId] = emptyObjectPatch(objectId, docState.objectMeta[objectId].type);\n  const patch = patches[objectId]; // Updating a list or text object (with elemId key)\n\n  if (op[keyStrIdx] === null) {\n    // If we come across any document op that was previously non-overwritten/non-deleted, that\n    // means the current list element already had a value before this change was applied, and\n    // therefore the current element cannot be an insert. If we already registered an insert, we\n    // have to convert it into an update.\n    if (oldSuccNum === 0 && !isWholeDoc && propState[elemId].action === 'insert') {\n      propState[elemId].action = 'update';\n      convertInsertToUpdate(patch.edits, listIndex, elemId);\n\n      if (newBlock && newBlock.lastObjectActor === op[objActorIdx] && newBlock.lastObjectCtr === op[objCtrIdx]) {\n        newBlock.numVisible -= 1;\n      }\n    }\n\n    if (patchValue) {\n      // If the op has a non-overwritten value and it came from the change, it's an insert.\n      // (It's not necessarily the case that op[insertIdx] is true: if a list element is concurrently\n      // deleted and updated, the node that first processes the deletion and then the update will\n      // observe the update as a re-insertion of the deleted list element.)\n      if (!propState[elemId].action && (oldSuccNum === undefined || isWholeDoc)) {\n        propState[elemId].action = 'insert';\n        appendEdit(patch.edits, {\n          action: 'insert',\n          index: listIndex,\n          elemId,\n          opId: patchKey,\n          value: patchValue\n        });\n\n        if (newBlock && newBlock.lastObjectActor === op[objActorIdx] && newBlock.lastObjectCtr === op[objCtrIdx]) {\n          newBlock.numVisible += 1;\n        } // If the property has a value and it's not an insert, then it must be an update.\n        // We might have previously registered it as a remove, in which case we convert it to update.\n\n      } else if (propState[elemId].action === 'remove') {\n        let lastEdit = patch.edits[patch.edits.length - 1];\n        if (lastEdit.action !== 'remove') throw new RangeError('last edit has unexpected type');\n        if (lastEdit.count > 1) lastEdit.count -= 1;else patch.edits.pop();\n        propState[elemId].action = 'update';\n        appendUpdate(patch.edits, listIndex, elemId, patchKey, patchValue, true);\n\n        if (newBlock && newBlock.lastObjectActor === op[objActorIdx] && newBlock.lastObjectCtr === op[objCtrIdx]) {\n          newBlock.numVisible += 1;\n        }\n      } else {\n        // A 'normal' update\n        appendUpdate(patch.edits, listIndex, elemId, patchKey, patchValue, !propState[elemId].action);\n        if (!propState[elemId].action) propState[elemId].action = 'update';\n      }\n    } else if (oldSuccNum === 0 && !propState[elemId].action) {\n      // If the property used to have a non-overwritten/non-deleted value, but no longer, it's a remove\n      propState[elemId].action = 'remove';\n      appendEdit(patch.edits, {\n        action: 'remove',\n        index: listIndex,\n        count: 1\n      });\n\n      if (newBlock && newBlock.lastObjectActor === op[objActorIdx] && newBlock.lastObjectCtr === op[objCtrIdx]) {\n        newBlock.numVisible -= 1;\n      }\n    }\n  } else if (patchValue || !isWholeDoc) {\n    // Updating a map or table (with string key)\n    if (firstOp || !patch.props[op[keyStrIdx]]) patch.props[op[keyStrIdx]] = {};\n    if (patchValue) patch.props[op[keyStrIdx]][patchKey] = patchValue;\n  }\n}\n/**\n * Applies operations (from one or more changes) to the document by merging the sequence of change\n * ops into the sequence of document ops. The two inputs are `changeState` and `docState`\n * respectively. Assumes that the decoders of both sets of columns are at the position where we want\n * to start merging. `patches` is mutated to reflect the effect of the change operations. `ops` is\n * the operation sequence to apply (as decoded by `groupRelatedOps()`). `docState` is as\n * documented in `applyOps()`. If the operations are updating a list or text object, `listIndex`\n * is the number of visible elements that precede the position at which we start merging.\n * `blockIndex` is the document block number from which we are currently reading.\n */\n\n\nfunction mergeDocChangeOps(patches, newBlock, outCols, changeState, docState, listIndex, blockIndex) {\n  const firstOp = changeState.nextOp,\n        insert = firstOp[insertIdx];\n  const objActor = firstOp[objActorIdx],\n        objCtr = firstOp[objCtrIdx];\n  const objectId = objActor === null ? '_root' : `${objCtr}@${docState.actorIds[objActor]}`;\n  const idActorIndex = changeState.actorIndex,\n        idActor = docState.actorIds[idActorIndex];\n  let foundListElem = false,\n      elemVisible = false,\n      propState = {},\n      docOp;\n  ({\n    docOp,\n    blockIndex\n  } = readNextDocOp(docState, blockIndex));\n  let docOpsConsumed = docOp === null ? 0 : 1;\n  let docOpOldSuccNum = docOp === null ? 0 : docOp[succNumIdx];\n  let changeOp = null,\n      changeOps = [],\n      changeCols = [],\n      predSeen = [],\n      lastChangeKey = null;\n  changeState.objectIds.add(objectId); // Merge the two inputs: the sequence of ops in the doc, and the sequence of ops in the change.\n  // At each iteration, we either output the doc's op (possibly updated based on the change's ops)\n  // or output an op from the change.\n\n  while (true) {\n    // The array `changeOps` contains operations from the change(s) we're applying. When the array\n    // is empty, we load changes from the change. Typically we load only a single operation at a\n    // time, with two exceptions: 1. all operations that update the same key or list element in the\n    // same object are put into changeOps at the same time (this is needed so that we can update the\n    // succ columns of the document ops correctly); 2. a run of consecutive insertions is also\n    // placed into changeOps in one go.\n    //\n    // When we have processed all the ops in changeOps we try to see whether there are further\n    // operations that we can also process while we're at it. Those operations must be for the same\n    // object, they must be for a key or list element that appears later in the document, they must\n    // either all be insertions or all be non-insertions, and if insertions, they must be\n    // consecutive. If these conditions are satisfied, that means the operations can be processed in\n    // the same pass. If we encounter an operation that does not meet these conditions, we leave\n    // changeOps empty, and this function returns after having processed any remaining document ops.\n    //\n    // Any operations that could not be processed in a single pass remain in changeState; applyOps\n    // will seek to the appropriate position and then call mergeDocChangeOps again.\n    if (changeOps.length === 0) {\n      foundListElem = false;\n      let nextOp = changeState.nextOp;\n\n      while (!changeState.done && nextOp[idActorIdx] === idActorIndex && nextOp[insertIdx] === insert && nextOp[objActorIdx] === firstOp[objActorIdx] && nextOp[objCtrIdx] === firstOp[objCtrIdx]) {\n        // Check if the operation's pred references a previous operation in changeOps\n        const lastOp = changeOps.length > 0 ? changeOps[changeOps.length - 1] : null;\n        let isOverwrite = false;\n\n        for (let i = 0; i < nextOp[predNumIdx]; i++) {\n          for (let prevOp of changeOps) {\n            if (nextOp[predActorIdx][i] === prevOp[idActorIdx] && nextOp[predCtrIdx][i] === prevOp[idCtrIdx]) {\n              isOverwrite = true;\n            }\n          }\n        } // If any of the following `if` statements is true, we add `nextOp` to `changeOps`. If they\n        // are all false, we break out of the loop and stop adding to `changeOps`.\n\n\n        if (nextOp === firstOp) {// First change operation in a mergeDocChangeOps call is always used\n        } else if (insert && lastOp !== null && nextOp[keyStrIdx] === null && nextOp[keyActorIdx] === lastOp[idActorIdx] && nextOp[keyCtrIdx] === lastOp[idCtrIdx]) {// Collect consecutive insertions\n        } else if (!insert && lastOp !== null && nextOp[keyStrIdx] !== null && nextOp[keyStrIdx] === lastOp[keyStrIdx] && !isOverwrite) {// Collect several updates to the same key\n        } else if (!insert && lastOp !== null && nextOp[keyStrIdx] === null && lastOp[keyStrIdx] === null && nextOp[keyActorIdx] === lastOp[keyActorIdx] && nextOp[keyCtrIdx] === lastOp[keyCtrIdx] && !isOverwrite) {// Collect several updates to the same list element\n        } else if (!insert && lastOp === null && nextOp[keyStrIdx] === null && docOp && docOp[insertIdx] && docOp[keyStrIdx] === null && docOp[idActorIdx] === nextOp[keyActorIdx] && docOp[idCtrIdx] === nextOp[keyCtrIdx]) {// When updating/deleting list elements, keep going if the next elemId in the change\n          // equals the next elemId in the doc (i.e. we're updating several consecutive elements)\n        } else if (!insert && lastOp === null && nextOp[keyStrIdx] !== null && lastChangeKey !== null && lastChangeKey < nextOp[keyStrIdx]) {// Allow a single mergeDocChangeOps call to process changes to several keys in the same\n          // object, provided that they appear in ascending order\n        } else break;\n\n        lastChangeKey = nextOp !== null ? nextOp[keyStrIdx] : null;\n        changeOps.push(changeState.nextOp);\n        changeCols.push(changeState.columns);\n        predSeen.push(new Array(changeState.nextOp[predNumIdx]));\n        readNextChangeOp(docState, changeState);\n        nextOp = changeState.nextOp;\n      }\n    }\n\n    if (changeOps.length > 0) changeOp = changeOps[0];\n    const inCorrectObject = docOp && docOp[objActorIdx] === changeOp[objActorIdx] && docOp[objCtrIdx] === changeOp[objCtrIdx];\n    const keyMatches = docOp && docOp[keyStrIdx] !== null && docOp[keyStrIdx] === changeOp[keyStrIdx];\n    const listElemMatches = docOp && docOp[keyStrIdx] === null && changeOp[keyStrIdx] === null && (!docOp[insertIdx] && docOp[keyActorIdx] === changeOp[keyActorIdx] && docOp[keyCtrIdx] === changeOp[keyCtrIdx] || docOp[insertIdx] && docOp[idActorIdx] === changeOp[keyActorIdx] && docOp[idCtrIdx] === changeOp[keyCtrIdx]); // We keep going until we run out of ops in the change, except that even when we run out, we\n    // keep going until we have processed all doc ops for the current key/list element.\n\n    if (changeOps.length === 0 && !(inCorrectObject && (keyMatches || listElemMatches))) break;\n    let takeDocOp = false,\n        takeChangeOps = 0; // The change operations come first if we are inserting list elements (seekToOp already\n    // determines the correct insertion position), if there is no document operation, if the next\n    // document operation is for a different object, or if the change op's string key is\n    // lexicographically first (TODO check ordering of keys beyond the basic multilingual plane).\n\n    if (insert || !inCorrectObject || docOp[keyStrIdx] === null && changeOp[keyStrIdx] !== null || docOp[keyStrIdx] !== null && changeOp[keyStrIdx] !== null && changeOp[keyStrIdx] < docOp[keyStrIdx]) {\n      // Take the operations from the change\n      takeChangeOps = changeOps.length;\n\n      if (!inCorrectObject && !foundListElem && changeOp[keyStrIdx] === null && !changeOp[insertIdx]) {\n        // This can happen if we first update one list element, then another one earlier in the\n        // list. That is not allowed: list element updates must occur in ascending order.\n        throw new RangeError(\"could not find list element with ID: \" + `${changeOp[keyCtrIdx]}@${docState.actorIds[changeOp[keyActorIdx]]}`);\n      }\n    } else if (keyMatches || listElemMatches || foundListElem) {\n      // The doc operation is for the same key or list element in the same object as the change\n      // ops, so we merge them. First, if any of the change ops' `pred` matches the opId of the\n      // document operation, we update the document operation's `succ` accordingly.\n      for (let opIndex = 0; opIndex < changeOps.length; opIndex++) {\n        const op = changeOps[opIndex];\n\n        for (let i = 0; i < op[predNumIdx]; i++) {\n          if (op[predActorIdx][i] === docOp[idActorIdx] && op[predCtrIdx][i] === docOp[idCtrIdx]) {\n            // Insert into the doc op's succ list such that the lists remains sorted\n            let j = 0;\n\n            while (j < docOp[succNumIdx] && (docOp[succCtrIdx][j] < op[idCtrIdx] || docOp[succCtrIdx][j] === op[idCtrIdx] && docState.actorIds[docOp[succActorIdx][j]] < idActor)) j++;\n\n            docOp[succCtrIdx].splice(j, 0, op[idCtrIdx]);\n            docOp[succActorIdx].splice(j, 0, idActorIndex);\n            docOp[succNumIdx]++;\n            predSeen[opIndex][i] = true;\n            break;\n          }\n        }\n      }\n\n      if (listElemMatches) foundListElem = true;\n\n      if (foundListElem && !listElemMatches) {\n        // If the previous docOp was for the correct list element, and the current docOp is for\n        // the wrong list element, then place the current changeOp before the docOp.\n        takeChangeOps = changeOps.length;\n      } else if (changeOps.length === 0 || docOp[idCtrIdx] < changeOp[idCtrIdx] || docOp[idCtrIdx] === changeOp[idCtrIdx] && docState.actorIds[docOp[idActorIdx]] < idActor) {\n        // When we have several operations for the same object and the same key, we want to keep\n        // them sorted in ascending order by opId. Here we have docOp with a lower opId, so we\n        // output it first.\n        takeDocOp = true;\n        updatePatchProperty(patches, newBlock, objectId, docOp, docState, propState, listIndex, docOpOldSuccNum); // A deletion op in the change is represented in the document only by its entries in the\n        // succ list of the operations it overwrites; it has no separate row in the set of ops.\n\n        for (let i = changeOps.length - 1; i >= 0; i--) {\n          let deleted = true;\n\n          for (let j = 0; j < changeOps[i][predNumIdx]; j++) {\n            if (!predSeen[i][j]) deleted = false;\n          }\n\n          if (ACTIONS[changeOps[i][actionIdx]] === 'del' && deleted) {\n            changeOps.splice(i, 1);\n            changeCols.splice(i, 1);\n            predSeen.splice(i, 1);\n          }\n        }\n      } else if (docOp[idCtrIdx] === changeOp[idCtrIdx] && docState.actorIds[docOp[idActorIdx]] === idActor) {\n        throw new RangeError(`duplicate operation ID: ${changeOp[idCtrIdx]}@${idActor}`);\n      } else {\n        // The changeOp has the lower opId, so we output it first.\n        takeChangeOps = 1;\n      }\n    } else {\n      // The document operation comes first if its string key is lexicographically first, or if\n      // we're using opId keys and the keys don't match (i.e. we scan the document until we find a\n      // matching key).\n      takeDocOp = true;\n    }\n\n    if (takeDocOp) {\n      appendOperation(outCols, docState.blocks[blockIndex].columns, docOp);\n      addBlockOperation(newBlock, docOp, docState.actorIds, false);\n\n      if (docOp[insertIdx] && elemVisible) {\n        elemVisible = false;\n        listIndex++;\n      }\n\n      if (docOp[succNumIdx] === 0) elemVisible = true;\n      newBlock.numOps++;\n      ({\n        docOp,\n        blockIndex\n      } = readNextDocOp(docState, blockIndex));\n\n      if (docOp !== null) {\n        docOpsConsumed++;\n        docOpOldSuccNum = docOp[succNumIdx];\n      }\n    }\n\n    if (takeChangeOps > 0) {\n      for (let i = 0; i < takeChangeOps; i++) {\n        let op = changeOps[i]; // Check that we've seen all ops mentioned in `pred` (they must all have lower opIds than\n        // the change op's own opId, so we must have seen them already)\n\n        for (let j = 0; j < op[predNumIdx]; j++) {\n          if (!predSeen[i][j]) {\n            throw new RangeError(`no matching operation for pred: ${op[predCtrIdx][j]}@${docState.actorIds[op[predActorIdx][j]]}`);\n          }\n        }\n\n        appendOperation(outCols, changeCols[i], op);\n        addBlockOperation(newBlock, op, docState.actorIds, true);\n        updatePatchProperty(patches, newBlock, objectId, op, docState, propState, listIndex);\n\n        if (op[insertIdx]) {\n          elemVisible = false;\n          listIndex++;\n        } else {\n          elemVisible = true;\n        }\n      }\n\n      if (takeChangeOps === changeOps.length) {\n        changeOps.length = 0;\n        changeCols.length = 0;\n        predSeen.length = 0;\n      } else {\n        changeOps.splice(0, takeChangeOps);\n        changeCols.splice(0, takeChangeOps);\n        predSeen.splice(0, takeChangeOps);\n      }\n\n      newBlock.numOps += takeChangeOps;\n    }\n  }\n\n  if (docOp) {\n    appendOperation(outCols, docState.blocks[blockIndex].columns, docOp);\n    newBlock.numOps++;\n    addBlockOperation(newBlock, docOp, docState.actorIds, false);\n  }\n\n  return {\n    docOpsConsumed,\n    blockIndex\n  };\n}\n/**\n * Applies operations from the change (or series of changes) in `changeState` to the document\n * `docState`. Passing `changeState` to `readNextChangeOp` allows iterating over the change ops.\n * `docState` is an object with keys:\n *   - `actorIds` is an array of actorIds (as hex strings) occurring in the document (values in\n *     the document's objActor/keyActor/idActor/... columns are indexes into this array).\n *   - `blocks` is an array of all the blocks of operations in the document.\n *   - `objectMeta` is a map from objectId to metadata about that object.\n *\n * `docState` is mutated to contain the updated document state.\n * `patches` is a patch object that is mutated to reflect the operations applied by this function.\n */\n\n\nfunction applyOps(patches, changeState, docState) {\n  const [objActorNum, objCtr, keyActorNum, keyCtr, keyStr, idActorNum, idCtr, insert] = changeState.nextOp;\n  const objActor = objActorNum === null ? null : docState.actorIds[objActorNum];\n  const keyActor = keyActorNum === null ? null : docState.actorIds[keyActorNum];\n  const ops = {\n    objActor,\n    objActorNum,\n    objCtr,\n    keyActor,\n    keyActorNum,\n    keyCtr,\n    keyStr,\n    idActor: docState.actorIds[idActorNum],\n    idCtr,\n    insert,\n    objId: objActor === null ? '_root' : `${objCtr}@${objActor}`\n  };\n  const {\n    blockIndex,\n    skipCount,\n    visibleCount\n  } = seekToOp(docState, ops);\n  const block = docState.blocks[blockIndex];\n\n  for (let col of block.columns) col.decoder.reset();\n\n  const resetFirstVisible = skipCount === 0 || block.firstVisibleActor === undefined || !insert && block.firstVisibleActor === keyActorNum && block.firstVisibleCtr === keyCtr;\n  const newBlock = {\n    columns: undefined,\n    bloom: new Uint8Array(block.bloom),\n    numOps: skipCount,\n    lastKey: block.lastKey,\n    numVisible: block.numVisible,\n    lastObjectActor: block.lastObjectActor,\n    lastObjectCtr: block.lastObjectCtr,\n    firstVisibleActor: resetFirstVisible ? undefined : block.firstVisibleActor,\n    firstVisibleCtr: resetFirstVisible ? undefined : block.firstVisibleCtr,\n    lastVisibleActor: undefined,\n    lastVisibleCtr: undefined\n  }; // Copy the operations up to the insertion position (the first skipCount operations)\n\n  const outCols = block.columns.map(col => ({\n    columnId: col.columnId,\n    encoder: encoderByColumnId(col.columnId)\n  }));\n  copyColumns(outCols, block.columns, skipCount); // Apply the operations from the change. This may cause blockIndex to move forwards if the\n  // property being updated straddles a block boundary.\n\n  const {\n    blockIndex: lastBlockIndex,\n    docOpsConsumed\n  } = mergeDocChangeOps(patches, newBlock, outCols, changeState, docState, visibleCount, blockIndex); // Copy the remaining operations after the insertion position\n\n  const lastBlock = docState.blocks[lastBlockIndex];\n  let copyAfterMerge = -skipCount - docOpsConsumed;\n\n  for (let i = blockIndex; i <= lastBlockIndex; i++) copyAfterMerge += docState.blocks[i].numOps;\n\n  copyColumns(outCols, lastBlock.columns, copyAfterMerge);\n  newBlock.numOps += copyAfterMerge;\n\n  for (let col of lastBlock.columns) {\n    if (!col.decoder.done) throw new RangeError(`excess ops in column ${col.columnId}`);\n  }\n\n  newBlock.columns = outCols.map(col => {\n    const decoder = decoderByColumnId(col.columnId, col.encoder.buffer);\n    return {\n      columnId: col.columnId,\n      decoder\n    };\n  });\n\n  if (blockIndex === lastBlockIndex && newBlock.numOps <= MAX_BLOCK_SIZE) {\n    // The result is just one output block\n    if (copyAfterMerge > 0 && block.lastVisibleActor !== undefined && block.lastVisibleCtr !== undefined) {\n      // It's possible that none of the ops after the merge point are visible, in which case the\n      // lastVisible may not be strictly correct, because it may refer to an operation before the\n      // merge point rather than a list element inserted by the current change. However, this doesn't\n      // matter, because the only purpose for which we need it is to check whether one block ends with\n      // the same visible element as the next block starts with (to avoid double-counting its index);\n      // if the last list element of a block is invisible, the exact value of lastVisible doesn't\n      // matter since it will be different from the next block's firstVisible in any case.\n      newBlock.lastVisibleActor = block.lastVisibleActor;\n      newBlock.lastVisibleCtr = block.lastVisibleCtr;\n    }\n\n    docState.blocks[blockIndex] = newBlock;\n  } else {\n    // Oversized output block must be split into smaller blocks\n    const newBlocks = splitBlock(newBlock);\n    docState.blocks.splice(blockIndex, lastBlockIndex - blockIndex + 1, ...newBlocks);\n  }\n}\n/**\n * Updates the columns in a document's operation blocks to contain all the columns in a change\n * (including any column types we don't recognise, which have been generated by a future version\n * of Automerge).\n */\n\n\nfunction updateBlockColumns(docState, changeCols) {\n  // Check that the columns of a change appear at the index at which we expect them to be\n  if (changeCols[objActorIdx].columnId !== CHANGE_COLUMNS[objActorIdx].columnId || CHANGE_COLUMNS[objActorIdx].columnName !== 'objActor' || changeCols[objCtrIdx].columnId !== CHANGE_COLUMNS[objCtrIdx].columnId || CHANGE_COLUMNS[objCtrIdx].columnName !== 'objCtr' || changeCols[keyActorIdx].columnId !== CHANGE_COLUMNS[keyActorIdx].columnId || CHANGE_COLUMNS[keyActorIdx].columnName !== 'keyActor' || changeCols[keyCtrIdx].columnId !== CHANGE_COLUMNS[keyCtrIdx].columnId || CHANGE_COLUMNS[keyCtrIdx].columnName !== 'keyCtr' || changeCols[keyStrIdx].columnId !== CHANGE_COLUMNS[keyStrIdx].columnId || CHANGE_COLUMNS[keyStrIdx].columnName !== 'keyStr' || changeCols[idActorIdx].columnId !== CHANGE_COLUMNS[idActorIdx].columnId || CHANGE_COLUMNS[idActorIdx].columnName !== 'idActor' || changeCols[idCtrIdx].columnId !== CHANGE_COLUMNS[idCtrIdx].columnId || CHANGE_COLUMNS[idCtrIdx].columnName !== 'idCtr' || changeCols[insertIdx].columnId !== CHANGE_COLUMNS[insertIdx].columnId || CHANGE_COLUMNS[insertIdx].columnName !== 'insert' || changeCols[actionIdx].columnId !== CHANGE_COLUMNS[actionIdx].columnId || CHANGE_COLUMNS[actionIdx].columnName !== 'action' || changeCols[valLenIdx].columnId !== CHANGE_COLUMNS[valLenIdx].columnId || CHANGE_COLUMNS[valLenIdx].columnName !== 'valLen' || changeCols[valRawIdx].columnId !== CHANGE_COLUMNS[valRawIdx].columnId || CHANGE_COLUMNS[valRawIdx].columnName !== 'valRaw' || changeCols[predNumIdx].columnId !== CHANGE_COLUMNS[predNumIdx].columnId || CHANGE_COLUMNS[predNumIdx].columnName !== 'predNum' || changeCols[predActorIdx].columnId !== CHANGE_COLUMNS[predActorIdx].columnId || CHANGE_COLUMNS[predActorIdx].columnName !== 'predActor' || changeCols[predCtrIdx].columnId !== CHANGE_COLUMNS[predCtrIdx].columnId || CHANGE_COLUMNS[predCtrIdx].columnName !== 'predCtr') {\n    throw new RangeError('unexpected columnId');\n  } // Check if there any columns in the change that are not in the document, apart from pred*\n\n\n  const docCols = docState.blocks[0].columns;\n\n  if (!changeCols.every(changeCol => PRED_COLUMN_IDS.includes(changeCol.columnId) || docCols.find(docCol => docCol.columnId === changeCol.columnId))) {\n    let allCols = docCols.map(docCol => ({\n      columnId: docCol.columnId\n    }));\n\n    for (let changeCol of changeCols) {\n      const {\n        columnId\n      } = changeCol;\n\n      if (!PRED_COLUMN_IDS.includes(columnId) && !docCols.find(docCol => docCol.columnId === columnId)) {\n        allCols.push({\n          columnId\n        });\n      }\n    }\n\n    allCols.sort((a, b) => a.columnId - b.columnId);\n\n    for (let blockIndex = 0; blockIndex < docState.blocks.length; blockIndex++) {\n      let block = copyObject(docState.blocks[blockIndex]);\n      block.columns = makeDecoders(block.columns.map(col => ({\n        columnId: col.columnId,\n        buffer: col.decoder.buf\n      })), allCols);\n      docState.blocks[blockIndex] = block;\n    }\n  }\n}\n/**\n * Takes a decoded change header, including an array of actorIds. Returns an object of the form\n * `{actorIds, actorTable}`, where `actorIds` is an updated array of actorIds appearing in the\n * document (including the new change's actorId). `actorTable` is an array of integers where\n * `actorTable[i]` contains the document's actor index for the actor that has index `i` in the\n * change (`i == 0` is the author of the change).\n */\n\n\nfunction getActorTable(actorIds, change) {\n  if (actorIds.indexOf(change.actorIds[0]) < 0) {\n    if (change.seq !== 1) {\n      throw new RangeError(`Seq ${change.seq} is the first change for actor ${change.actorIds[0]}`);\n    } // Use concat, not push, so that the original array is not mutated\n\n\n    actorIds = actorIds.concat([change.actorIds[0]]);\n  }\n\n  const actorTable = []; // translate from change's actor index to doc's actor index\n\n  for (let actorId of change.actorIds) {\n    const index = actorIds.indexOf(actorId);\n\n    if (index < 0) {\n      throw new RangeError(`actorId ${actorId} is not known to document`);\n    }\n\n    actorTable.push(index);\n  }\n\n  return {\n    actorIds,\n    actorTable\n  };\n}\n/**\n * Finalises the patch for a change. `patches` is a map from objectIds to patch for that\n * particular object, `objectIds` is the array of IDs of objects that are created or updated in the\n * change, and `docState` is an object containing various bits of document state, including\n * `objectMeta`, a map from objectIds to metadata about that object (such as its parent in the\n * document tree). Mutates `patches` such that child objects are linked into their parent object,\n * all the way to the root object.\n */\n\n\nfunction setupPatches(patches, objectIds, docState) {\n  for (let objectId of objectIds) {\n    let meta = docState.objectMeta[objectId],\n        childMeta = null,\n        patchExists = false;\n\n    while (true) {\n      const hasChildren = childMeta && Object.keys(meta.children[childMeta.parentKey]).length > 0;\n      if (!patches[objectId]) patches[objectId] = emptyObjectPatch(objectId, meta.type);\n\n      if (childMeta && hasChildren) {\n        if (meta.type === 'list' || meta.type === 'text') {\n          // In list/text objects, parentKey is an elemID. First see if it already appears in an edit\n          for (let edit of patches[objectId].edits) {\n            if (edit.opId && meta.children[childMeta.parentKey][edit.opId]) {\n              patchExists = true;\n            }\n          } // If we need to add an edit, we first have to translate the elemId into an index\n\n\n          if (!patchExists) {\n            const obj = parseOpId(objectId),\n                  elem = parseOpId(childMeta.parentKey);\n            const seekPos = {\n              objActor: obj.actorId,\n              objCtr: obj.counter,\n              keyActor: elem.actorId,\n              keyCtr: elem.counter,\n              objActorNum: docState.actorIds.indexOf(obj.actorId),\n              keyActorNum: docState.actorIds.indexOf(elem.actorId),\n              keyStr: null,\n              insert: false,\n              objId: objectId\n            };\n            const {\n              visibleCount\n            } = seekToOp(docState, seekPos);\n\n            for (let [opId, value] of Object.entries(meta.children[childMeta.parentKey])) {\n              let patchValue = value;\n\n              if (value.objectId) {\n                if (!patches[value.objectId]) patches[value.objectId] = emptyObjectPatch(value.objectId, value.type);\n                patchValue = patches[value.objectId];\n              }\n\n              const edit = {\n                action: 'update',\n                index: visibleCount,\n                opId,\n                value: patchValue\n              };\n              appendEdit(patches[objectId].edits, edit);\n            }\n          }\n        } else {\n          // Non-list object: parentKey is the name of the property being updated (a string)\n          if (!patches[objectId].props[childMeta.parentKey]) {\n            patches[objectId].props[childMeta.parentKey] = {};\n          }\n\n          let values = patches[objectId].props[childMeta.parentKey];\n\n          for (let [opId, value] of Object.entries(meta.children[childMeta.parentKey])) {\n            if (values[opId]) {\n              patchExists = true;\n            } else if (value.objectId) {\n              if (!patches[value.objectId]) patches[value.objectId] = emptyObjectPatch(value.objectId, value.type);\n              values[opId] = patches[value.objectId];\n            } else {\n              values[opId] = value;\n            }\n          }\n        }\n      }\n\n      if (patchExists || !meta.parentObj || childMeta && !hasChildren) break;\n      childMeta = meta;\n      objectId = meta.parentObj;\n      meta = docState.objectMeta[objectId];\n    }\n  }\n\n  return patches;\n}\n/**\n * Takes an array of decoded changes and applies them to a document. `docState` contains a bunch of\n * fields describing the document state. This function mutates `docState` to contain the updated\n * document state, and mutates `patches` to contain a patch to return to the frontend. Only the\n * top-level `docState` object is mutated; all nested objects within it are treated as immutable.\n * `objectIds` is mutated to contain the IDs of objects that are updated in any of the changes.\n *\n * The function detects duplicate changes that we've already applied by looking up each change's\n * hash in `docState.changeIndexByHash`. If we deferred the hash graph computation, that structure\n * will be incomplete, and we run the risk of applying the same change twice. However, we still have\n * the sequence numbers for detecting duplicates. If `throwExceptions` is true, we assume that the\n * set of change hashes is complete, and therefore a duplicate sequence number indicates illegal\n * behaviour. If `throwExceptions` is false, and we detect a possible sequence number reuse, we\n * don't throw an exception but instead enqueue all of the changes. This gives us a chance to\n * recompute the hash graph and eliminate duplicates before raising an error to the application.\n *\n * Returns a two-element array `[applied, enqueued]`, where `applied` is an array of changes that\n * have been applied to the document, and `enqueued` is an array of changes that have not yet been\n * applied because they are missing a dependency.\n */\n\n\nfunction applyChanges(patches, decodedChanges, docState, objectIds, throwExceptions) {\n  let heads = new Set(docState.heads),\n      changeHashes = new Set();\n  let clock = copyObject(docState.clock);\n  let applied = [],\n      enqueued = [];\n\n  for (let change of decodedChanges) {\n    // Skip any duplicate changes that we have already seen\n    if (docState.changeIndexByHash[change.hash] !== undefined || changeHashes.has(change.hash)) continue;\n    const expectedSeq = (clock[change.actor] || 0) + 1;\n    let causallyReady = true;\n\n    for (let dep of change.deps) {\n      const depIndex = docState.changeIndexByHash[dep];\n\n      if ((depIndex === undefined || depIndex === -1) && !changeHashes.has(dep)) {\n        causallyReady = false;\n      }\n    }\n\n    if (!causallyReady) {\n      enqueued.push(change);\n    } else if (change.seq < expectedSeq) {\n      if (throwExceptions) {\n        throw new RangeError(`Reuse of sequence number ${change.seq} for actor ${change.actor}`);\n      } else {\n        return [[], decodedChanges];\n      }\n    } else if (change.seq > expectedSeq) {\n      throw new RangeError(`Skipped sequence number ${expectedSeq} for actor ${change.actor}`);\n    } else {\n      clock[change.actor] = change.seq;\n      changeHashes.add(change.hash);\n\n      for (let dep of change.deps) heads.delete(dep);\n\n      heads.add(change.hash);\n      applied.push(change);\n    }\n  }\n\n  if (applied.length > 0) {\n    let changeState = {\n      changes: applied,\n      changeIndex: -1,\n      objectIds\n    };\n    readNextChangeOp(docState, changeState);\n\n    while (!changeState.done) applyOps(patches, changeState, docState);\n\n    docState.heads = [...heads].sort();\n    docState.clock = clock;\n  }\n\n  return [applied, enqueued];\n}\n/**\n * Scans the operations in a document and generates a patch that can be sent to the frontend to\n * instantiate the current state of the document. `objectMeta` is mutated to contain information\n * about the parent and children of each object in the document.\n */\n\n\nfunction documentPatch(docState) {\n  for (let col of docState.blocks[0].columns) col.decoder.reset();\n\n  let propState = {},\n      docOp = null,\n      blockIndex = 0;\n  let patches = {\n    _root: {\n      objectId: '_root',\n      type: 'map',\n      props: {}\n    }\n  };\n  let lastObjActor = null,\n      lastObjCtr = null,\n      objectId = '_root',\n      elemVisible = false,\n      listIndex = 0;\n\n  while (true) {\n    ({\n      docOp,\n      blockIndex\n    } = readNextDocOp(docState, blockIndex));\n    if (docOp === null) break;\n\n    if (docOp[objActorIdx] !== lastObjActor || docOp[objCtrIdx] !== lastObjCtr) {\n      objectId = `${docOp[objCtrIdx]}@${docState.actorIds[docOp[objActorIdx]]}`;\n      lastObjActor = docOp[objActorIdx];\n      lastObjCtr = docOp[objCtrIdx];\n      propState = {};\n      listIndex = 0;\n      elemVisible = false;\n    }\n\n    if (docOp[insertIdx] && elemVisible) {\n      elemVisible = false;\n      listIndex++;\n    }\n\n    if (docOp[succNumIdx] === 0) elemVisible = true;\n    if (docOp[idCtrIdx] > docState.maxOp) docState.maxOp = docOp[idCtrIdx];\n\n    for (let i = 0; i < docOp[succNumIdx]; i++) {\n      if (docOp[succCtrIdx][i] > docState.maxOp) docState.maxOp = docOp[succCtrIdx][i];\n    }\n\n    updatePatchProperty(patches, null, objectId, docOp, docState, propState, listIndex, docOp[succNumIdx]);\n  }\n\n  return patches._root;\n}\n/**\n * Takes an encoded document whose headers have been parsed using `decodeDocumentHeader()` and reads\n * from it the list of changes. Returns the document's current vector clock, i.e. an object mapping\n * each actor ID (as a hex string) to the number of changes seen from that actor. Also returns an\n * array of the actorIds whose most recent change has no dependents (i.e. the actors that\n * contributed the current heads of the document), and an array of encoders that has been\n * initialised to contain the columns of the changes list.\n */\n\n\nfunction readDocumentChanges(doc) {\n  const columns = makeDecoders(doc.changesColumns, DOCUMENT_COLUMNS);\n  const actorD = columns[0].decoder,\n        seqD = columns[1].decoder;\n  const depsNumD = columns[5].decoder,\n        depsIndexD = columns[6].decoder;\n\n  if (columns[0].columnId !== DOCUMENT_COLUMNS[0].columnId || DOCUMENT_COLUMNS[0].columnName !== 'actor' || columns[1].columnId !== DOCUMENT_COLUMNS[1].columnId || DOCUMENT_COLUMNS[1].columnName !== 'seq' || columns[5].columnId !== DOCUMENT_COLUMNS[5].columnId || DOCUMENT_COLUMNS[5].columnName !== 'depsNum' || columns[6].columnId !== DOCUMENT_COLUMNS[6].columnId || DOCUMENT_COLUMNS[6].columnName !== 'depsIndex') {\n    throw new RangeError('unexpected columnId');\n  }\n\n  let numChanges = 0,\n      clock = {},\n      actorNums = [],\n      headIndexes = new Set();\n\n  while (!actorD.done) {\n    const actorNum = actorD.readValue(),\n          seq = seqD.readValue(),\n          depsNum = depsNumD.readValue();\n    const actorId = doc.actorIds[actorNum];\n\n    if (seq !== 1 && seq !== clock[actorId] + 1) {\n      throw new RangeError(`Expected seq ${clock[actorId] + 1}, got ${seq} for actor ${actorId}`);\n    }\n\n    actorNums.push(actorNum);\n    clock[actorId] = seq;\n    headIndexes.add(numChanges);\n\n    for (let j = 0; j < depsNum; j++) headIndexes.delete(depsIndexD.readValue());\n\n    numChanges++;\n  }\n\n  const headActors = [...headIndexes].map(index => doc.actorIds[actorNums[index]]).sort();\n\n  for (let col of columns) col.decoder.reset();\n\n  const encoders = columns.map(col => ({\n    columnId: col.columnId,\n    encoder: encoderByColumnId(col.columnId)\n  }));\n  copyColumns(encoders, columns, numChanges);\n  return {\n    clock,\n    headActors,\n    encoders,\n    numChanges\n  };\n}\n/**\n * Records the metadata about a change in the appropriate columns.\n */\n\n\nfunction appendChange(columns, change, actorIds, changeIndexByHash) {\n  appendOperation(columns, DOCUMENT_COLUMNS, [actorIds.indexOf(change.actor), // actor\n  change.seq, // seq\n  change.maxOp, // maxOp\n  change.time, // time\n  change.message, // message\n  change.deps.length, // depsNum\n  change.deps.map(dep => changeIndexByHash[dep]), // depsIndex\n  change.extraBytes ? change.extraBytes.byteLength << 4 | VALUE_TYPE.BYTES : VALUE_TYPE.BYTES, // extraLen\n  change.extraBytes // extraRaw\n  ]);\n}\n\nclass BackendDoc {\n  constructor(buffer) {\n    this.maxOp = 0;\n    this.haveHashGraph = false;\n    this.changes = [];\n    this.changeIndexByHash = {};\n    this.dependenciesByHash = {};\n    this.dependentsByHash = {};\n    this.hashesByActor = {};\n    this.actorIds = [];\n    this.heads = [];\n    this.clock = {};\n    this.queue = [];\n    this.objectMeta = {\n      _root: {\n        parentObj: null,\n        parentKey: null,\n        opId: null,\n        type: 'map',\n        children: {}\n      }\n    };\n\n    if (buffer) {\n      const doc = decodeDocumentHeader(buffer);\n      const {\n        clock,\n        headActors,\n        encoders,\n        numChanges\n      } = readDocumentChanges(doc);\n      this.binaryDoc = buffer;\n      this.changes = new Array(numChanges);\n      this.actorIds = doc.actorIds;\n      this.heads = doc.heads;\n      this.clock = clock;\n      this.changesEncoders = encoders;\n      this.extraBytes = doc.extraBytes; // If there is a single head, we can unambiguously point at the actorId and sequence number of\n      // the head hash without having to reconstruct the hash graph\n\n      if (doc.heads.length === 1 && headActors.length === 1) {\n        this.hashesByActor[headActors[0]] = [];\n        this.hashesByActor[headActors[0]][clock[headActors[0]] - 1] = doc.heads[0];\n      } // The encoded document gives each change an index, and expresses dependencies in terms of\n      // those indexes. Initialise the translation table from hash to index.\n\n\n      if (doc.heads.length === doc.headsIndexes.length) {\n        for (let i = 0; i < doc.heads.length; i++) {\n          this.changeIndexByHash[doc.heads[i]] = doc.headsIndexes[i];\n        }\n      } else if (doc.heads.length === 1) {\n        // If there is only one head, it must be the last change\n        this.changeIndexByHash[doc.heads[0]] = numChanges - 1;\n      } else {\n        // We know the heads hashes, but not their indexes\n        for (let head of doc.heads) this.changeIndexByHash[head] = -1;\n      }\n\n      this.blocks = [{\n        columns: makeDecoders(doc.opsColumns, DOC_OPS_COLUMNS)\n      }];\n      updateBlockMetadata(this.blocks[0]);\n\n      if (this.blocks[0].numOps > MAX_BLOCK_SIZE) {\n        this.blocks = splitBlock(this.blocks[0]);\n      }\n\n      let docState = {\n        blocks: this.blocks,\n        actorIds: this.actorIds,\n        objectMeta: this.objectMeta,\n        maxOp: 0\n      };\n      this.initPatch = documentPatch(docState);\n      this.maxOp = docState.maxOp;\n    } else {\n      this.haveHashGraph = true;\n      this.changesEncoders = DOCUMENT_COLUMNS.map(col => ({\n        columnId: col.columnId,\n        encoder: encoderByColumnId(col.columnId)\n      }));\n      this.blocks = [{\n        columns: makeDecoders([], DOC_OPS_COLUMNS),\n        bloom: new Uint8Array(BLOOM_FILTER_SIZE),\n        numOps: 0,\n        lastKey: undefined,\n        numVisible: undefined,\n        lastObjectActor: undefined,\n        lastObjectCtr: undefined,\n        firstVisibleActor: undefined,\n        firstVisibleCtr: undefined,\n        lastVisibleActor: undefined,\n        lastVisibleCtr: undefined\n      }];\n    }\n  }\n  /**\n   * Makes a copy of this BackendDoc that can be independently modified.\n   */\n\n\n  clone() {\n    let copy = new BackendDoc();\n    copy.maxOp = this.maxOp;\n    copy.haveHashGraph = this.haveHashGraph;\n    copy.changes = this.changes.slice();\n    copy.changeIndexByHash = copyObject(this.changeIndexByHash);\n    copy.dependenciesByHash = copyObject(this.dependenciesByHash);\n    copy.dependentsByHash = Object.entries(this.dependentsByHash).reduce((acc, [k, v]) => {\n      acc[k] = v.slice();\n      return acc;\n    }, {});\n    copy.hashesByActor = Object.entries(this.hashesByActor).reduce((acc, [k, v]) => {\n      acc[k] = v.slice();\n      return acc;\n    }, {});\n    copy.actorIds = this.actorIds; // immutable, no copying needed\n\n    copy.heads = this.heads; // immutable, no copying needed\n\n    copy.clock = this.clock; // immutable, no copying needed\n\n    copy.blocks = this.blocks; // immutable, no copying needed\n\n    copy.objectMeta = this.objectMeta; // immutable, no copying needed\n\n    copy.queue = this.queue; // immutable, no copying needed\n\n    return copy;\n  }\n  /**\n   * Parses the changes given as Uint8Arrays in `changeBuffers`, and applies them to the current\n   * document. Returns a patch to apply to the frontend. If an exception is thrown, the document\n   * object is not modified.\n   */\n\n\n  applyChanges(changeBuffers, isLocal = false) {\n    // decoded change has the form { actor, seq, startOp, time, message, deps, actorIds, hash, columns, buffer }\n    let decodedChanges = changeBuffers.map(buffer => {\n      const decoded = decodeChangeColumns(buffer);\n      decoded.buffer = buffer;\n      return decoded;\n    });\n    let patches = {\n      _root: {\n        objectId: '_root',\n        type: 'map',\n        props: {}\n      }\n    };\n    let docState = {\n      maxOp: this.maxOp,\n      changeIndexByHash: this.changeIndexByHash,\n      actorIds: this.actorIds,\n      heads: this.heads,\n      clock: this.clock,\n      blocks: this.blocks.slice(),\n      objectMeta: Object.assign({}, this.objectMeta)\n    };\n    let queue = this.queue.length === 0 ? decodedChanges : decodedChanges.concat(this.queue);\n    let allApplied = [],\n        objectIds = new Set();\n\n    while (true) {\n      const [applied, enqueued] = applyChanges(patches, queue, docState, objectIds, this.haveHashGraph);\n      queue = enqueued;\n      if (applied.length > 0) allApplied = allApplied.concat(applied);\n      if (queue.length === 0) break; // If we are missing a dependency, and we haven't computed the hash graph yet, first compute\n      // the hashes to see if we actually have it already\n\n      if (applied.length === 0) {\n        if (this.haveHashGraph) break;\n        this.computeHashGraph();\n        docState.changeIndexByHash = this.changeIndexByHash;\n      }\n    }\n\n    setupPatches(patches, objectIds, docState); // Update the document state only if `applyChanges` does not throw an exception\n\n    for (let change of allApplied) {\n      this.changes.push(change.buffer);\n      if (!this.hashesByActor[change.actor]) this.hashesByActor[change.actor] = [];\n      this.hashesByActor[change.actor][change.seq - 1] = change.hash;\n      this.changeIndexByHash[change.hash] = this.changes.length - 1;\n      this.dependenciesByHash[change.hash] = change.deps;\n      this.dependentsByHash[change.hash] = [];\n\n      for (let dep of change.deps) {\n        if (!this.dependentsByHash[dep]) this.dependentsByHash[dep] = [];\n        this.dependentsByHash[dep].push(change.hash);\n      }\n\n      appendChange(this.changesEncoders, change, docState.actorIds, this.changeIndexByHash);\n    }\n\n    this.maxOp = docState.maxOp;\n    this.actorIds = docState.actorIds;\n    this.heads = docState.heads;\n    this.clock = docState.clock;\n    this.blocks = docState.blocks;\n    this.objectMeta = docState.objectMeta;\n    this.queue = queue;\n    this.binaryDoc = null;\n    this.initPatch = null;\n    let patch = {\n      maxOp: this.maxOp,\n      clock: this.clock,\n      deps: this.heads,\n      pendingChanges: this.queue.length,\n      diffs: patches._root\n    };\n\n    if (isLocal && decodedChanges.length === 1) {\n      patch.actor = decodedChanges[0].actor;\n      patch.seq = decodedChanges[0].seq;\n    }\n\n    return patch;\n  }\n  /**\n   * Reconstructs the full change history of a document, and initialises the variables that allow us\n   * to traverse the hash graph of changes and their dependencies. When a compressed document is\n   * loaded we defer the computation of this hash graph to make loading faster, but if the hash\n   * graph is later needed (e.g. for the sync protocol), this function fills it in.\n   */\n\n\n  computeHashGraph() {\n    const binaryDoc = this.save();\n    this.haveHashGraph = true;\n    this.changes = [];\n    this.changeIndexByHash = {};\n    this.dependenciesByHash = {};\n    this.dependentsByHash = {};\n    this.hashesByActor = {};\n    this.clock = {};\n\n    for (let change of decodeChanges([binaryDoc])) {\n      const binaryChange = encodeChange(change); // TODO: avoid decoding and re-encoding again\n\n      this.changes.push(binaryChange);\n      this.changeIndexByHash[change.hash] = this.changes.length - 1;\n      this.dependenciesByHash[change.hash] = change.deps;\n      this.dependentsByHash[change.hash] = [];\n\n      for (let dep of change.deps) this.dependentsByHash[dep].push(change.hash);\n\n      if (change.seq === 1) this.hashesByActor[change.actor] = [];\n      this.hashesByActor[change.actor].push(change.hash);\n      const expectedSeq = (this.clock[change.actor] || 0) + 1;\n\n      if (change.seq !== expectedSeq) {\n        throw new RangeError(`Expected seq ${expectedSeq}, got seq ${change.seq} from actor ${change.actor}`);\n      }\n\n      this.clock[change.actor] = change.seq;\n    }\n  }\n  /**\n   * Returns all the changes that need to be sent to another replica. `haveDeps` is a list of change\n   * hashes (as hex strings) of the heads that the other replica has. The changes in `haveDeps` and\n   * any of their transitive dependencies will not be returned; any changes later than or concurrent\n   * to the hashes in `haveDeps` will be returned. If `haveDeps` is an empty array, all changes are\n   * returned. Throws an exception if any of the given hashes are not known to this replica.\n   */\n\n\n  getChanges(haveDeps) {\n    if (!this.haveHashGraph) this.computeHashGraph(); // If the other replica has nothing, return all changes in history order\n\n    if (haveDeps.length === 0) {\n      return this.changes.slice();\n    } // Fast path for the common case where all new changes depend only on haveDeps\n\n\n    let stack = [],\n        seenHashes = {},\n        toReturn = [];\n\n    for (let hash of haveDeps) {\n      seenHashes[hash] = true;\n      const successors = this.dependentsByHash[hash];\n      if (!successors) throw new RangeError(`hash not found: ${hash}`);\n      stack.push(...successors);\n    } // Depth-first traversal of the hash graph to find all changes that depend on `haveDeps`\n\n\n    while (stack.length > 0) {\n      const hash = stack.pop();\n      seenHashes[hash] = true;\n      toReturn.push(hash);\n\n      if (!this.dependenciesByHash[hash].every(dep => seenHashes[dep])) {\n        // If a change depends on a hash we have not seen, abort the traversal and fall back to the\n        // slower algorithm. This will sometimes abort even if all new changes depend on `haveDeps`,\n        // because our depth-first traversal is not necessarily a topological sort of the graph.\n        break;\n      }\n\n      stack.push(...this.dependentsByHash[hash]);\n    } // If the traversal above has encountered all the heads, and was not aborted early due to\n    // a missing dependency, then the set of changes it has found is complete, so we can return it\n\n\n    if (stack.length === 0 && this.heads.every(head => seenHashes[head])) {\n      return toReturn.map(hash => this.changes[this.changeIndexByHash[hash]]);\n    } // If we haven't encountered all of the heads, we have to search harder. This will happen if\n    // changes were added that are concurrent to `haveDeps`\n\n\n    stack = haveDeps.slice();\n    seenHashes = {};\n\n    while (stack.length > 0) {\n      const hash = stack.pop();\n\n      if (!seenHashes[hash]) {\n        const deps = this.dependenciesByHash[hash];\n        if (!deps) throw new RangeError(`hash not found: ${hash}`);\n        stack.push(...deps);\n        seenHashes[hash] = true;\n      }\n    }\n\n    return this.changes.filter(change => !seenHashes[decodeChangeMeta(change, true).hash]);\n  }\n  /**\n   * Returns all changes that are present in this BackendDoc, but not present in the `other`\n   * BackendDoc.\n   */\n\n\n  getChangesAdded(other) {\n    if (!this.haveHashGraph) this.computeHashGraph(); // Depth-first traversal from the heads through the dependency graph,\n    // until we reach a change that is already present in opSet1\n\n    let stack = this.heads.slice(),\n        seenHashes = {},\n        toReturn = [];\n\n    while (stack.length > 0) {\n      const hash = stack.pop();\n\n      if (!seenHashes[hash] && other.changeIndexByHash[hash] === undefined) {\n        seenHashes[hash] = true;\n        toReturn.push(hash);\n        stack.push(...this.dependenciesByHash[hash]);\n      }\n    } // Return those changes in the reverse of the order in which the depth-first search\n    // found them. This is not necessarily a topological sort, but should usually be close.\n\n\n    return toReturn.reverse().map(hash => this.changes[this.changeIndexByHash[hash]]);\n  }\n\n  getChangeByHash(hash) {\n    if (!this.haveHashGraph) this.computeHashGraph();\n    return this.changes[this.changeIndexByHash[hash]];\n  }\n  /**\n   * Returns the hashes of any missing dependencies, i.e. where we have tried to apply a change that\n   * has a dependency on a change we have not seen.\n   *\n   * If the argument `heads` is given (an array of hexadecimal strings representing hashes as\n   * returned by `getHeads()`), this function also ensures that all of those hashes resolve to\n   * either a change that has been applied to the document, or that has been enqueued for later\n   * application once missing dependencies have arrived. Any missing heads hashes are included in\n   * the returned array.\n   */\n\n\n  getMissingDeps(heads = []) {\n    if (!this.haveHashGraph) this.computeHashGraph();\n    let allDeps = new Set(heads),\n        inQueue = new Set();\n\n    for (let change of this.queue) {\n      inQueue.add(change.hash);\n\n      for (let dep of change.deps) allDeps.add(dep);\n    }\n\n    let missing = [];\n\n    for (let hash of allDeps) {\n      if (this.changeIndexByHash[hash] === undefined && !inQueue.has(hash)) missing.push(hash);\n    }\n\n    return missing.sort();\n  }\n  /**\n   * Serialises the current document state into a single byte array.\n   */\n\n\n  save() {\n    if (this.binaryDoc) return this.binaryDoc; // Getting the byte array for the changes columns finalises their encoders, after which we can\n    // no longer append values to them. We therefore copy their data over to fresh encoders.\n\n    const newEncoders = this.changesEncoders.map(col => ({\n      columnId: col.columnId,\n      encoder: encoderByColumnId(col.columnId)\n    }));\n    const decoders = this.changesEncoders.map(col => {\n      const decoder = decoderByColumnId(col.columnId, col.encoder.buffer);\n      return {\n        columnId: col.columnId,\n        decoder\n      };\n    });\n    copyColumns(newEncoders, decoders, this.changes.length);\n    this.binaryDoc = encodeDocumentHeader({\n      changesColumns: this.changesEncoders,\n      opsColumns: concatBlocks(this.blocks),\n      actorIds: this.actorIds,\n      // TODO: sort actorIds (requires transforming all actorId columns in opsColumns)\n      heads: this.heads,\n      headsIndexes: this.heads.map(hash => this.changeIndexByHash[hash]),\n      extraBytes: this.extraBytes\n    });\n    this.changesEncoders = newEncoders;\n    return this.binaryDoc;\n  }\n  /**\n   * Returns a patch from which we can initialise the current state of the backend.\n   */\n\n\n  getPatch() {\n    const objectMeta = {\n      _root: {\n        parentObj: null,\n        parentKey: null,\n        opId: null,\n        type: 'map',\n        children: {}\n      }\n    };\n    const docState = {\n      blocks: this.blocks,\n      actorIds: this.actorIds,\n      objectMeta,\n      maxOp: 0\n    };\n    const diffs = this.initPatch ? this.initPatch : documentPatch(docState);\n    return {\n      maxOp: this.maxOp,\n      clock: this.clock,\n      deps: this.heads,\n      pendingChanges: this.queue.length,\n      diffs\n    };\n  }\n\n}\n\nmodule.exports = {\n  MAX_BLOCK_SIZE,\n  BackendDoc,\n  bloomFilterContains\n};","map":null,"metadata":{},"sourceType":"script"}